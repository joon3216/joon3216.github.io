<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Junkyu Park" />


<title>Dealing with a non-separable penalty</title>

<link href="non_separable_penalty_files/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="non_separable_penalty_files/pagedtable-1.1/js/pagedtable.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139050237-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-139050237-1');
</script>
<!-- A new navigation bar style settings -->
<style type="text/css">
body
{
    margin: 0;
    padding: 0;
    font-family: sans-serif;
}
/* at the top */
header
{
    position: sticky;
    top: 0;
    left: 0;
    padding: 0; /* old: 10px 25px */
    background: rgba(28, 44, 56, 0.99);
    width: 100%;
    height: 50px;
    box-sizing: border-box;
    border-bottom: 1px solid #EAEAEB;
    transition: .5s;
}
header .logo
{
    float: left;
}
header .logo img
{
    height: 30px;
    /* new: margin; why: so that in header, padding can be 0 */
    /* note: header nav ul li a has margin 20px on left and right, 
    so here I let the right margin of img to be 5px so that it matches
    with the left margin 25px */
    margin: 10px 5px 10px 25px; 
}
header nav
{
    float: left;
}
header nav ul
{
    margin: 0;
    padding: 0;
    display: flex;

}
header nav ul li
{
    padding: 0;
    list-style: none;
    position: relative;
    /* new: margin and padding; why: header padding is now 0 */
    margin: 0;
    padding: 8.5px 0 8.5px 0;
}
/* new; why: texts with arrow on the right gets more space  */
header nav ul li.sub-menu
{
    /* why 8.5px: that's the value in header nav ul li padding */
    padding: 8.5px 27.5px 8.5px 0;
    padding-bottom: 12px;
    /* new; why: to make dropdown menu available once the mouse is on the menu item that it belongs, and to not affect other menu items that is not of class sub-menu */
}

header nav ul li.sub-menu:before
{
    content: '\f0d7'; /* &#9660 ▼ nabla */
    font-family: fontAwesome; /* old: sans-serif */
    font-size: 16pt;
    position: absolute;
    /*line-height: 30px;*/
    color: #ffffff;
    top: 7pt;
    right: 22.5px;
    cursor: pointer;
}
header nav ul li.active.sub-menu:before
{
    content: '\f0d8';  /* &#9650 ▲ Delta */
    font-family: fontAwesome; /* new */
    font-size: 16pt;
    position: absolute;
    color: #ffffff;
    top: 7pt;
    right: 22.5px;
    cursor: pointer;
}
header nav ul li ul
{
    position: absolute;
    left: 0;
    top: 50px; /* controls the box position of dropdown menus */
    background: rgba(57, 143, 209, 0.99);
    display: none;
}
header nav ul li.active ul
{
    display: block;
}

/* new; why: make dropdown menu box fit to the menu above */
/* padding: 0; is for slimmer individual dropdown menu items */
/* old */
header nav ul li.sub-menu ul li
{
    display: block;
    width: 200px;
    padding: 5px 0;
}

/* new: header nav ul li ul li a */
/* why: giving an indentation */
header nav ul li ul li a
{
    margin: 0 40px;
}

/* header nav ul li#projects.sub-menu ul li
{
    display: block;
    width: 115px;
    padding: 0;
}
header nav ul li#rm.sub-menu ul li
{
    display: block;
    width: 197px;
    padding: 0;
} */

header nav ul li a
{
    height: 30px;
    line-height: 30px;
    padding: 0; /* old: 0 20px, and margin didn't exist; why change: to make text the only clickable object */
    margin: 0 20px;
    color: #ffffff;
    text-decoration: none;
    /*display: block;*/
}

/* new: news; why add: to make News go to the right */
/* commented out because the same effect is achieved by having 
header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
/* header nav ul li.news
{
    margin: 0 0 0 20px;
} */

/* new: rm; why: to make r_m go to the right */
/* commented out because the same effect is achieved by having 
header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
/* header nav ul li#rm
{
    margin: 0 0 0 20px;
} */

header nav ul li a:hover
{
    color: #ffffff;
}

/* new: header nav ul li:hover ul, why: to make dropdown menu appear whenever mouse is above */
header nav ul li:hover ul
{
    display: block;
}

.menu-toggle
{
    color: #ffffff;
    float: right;
    line-height: 30px;
    font-size: 24px;
    cursor: pointer;
    display: none;
}
@media (max-width: 800px) /* old1: 991px; old2: 721px */
{
    /* at the top */
    header
    {
        padding: 0; /* old: 10px 25px */
    }
    .menu-toggle
    {
        display: block;
        margin: 10px 25px /* new; why: header padding is now 0 */
    }
    header nav
    {
        /*display: none;*/
        position: absolute;
        width: 100%;
        height: calc(100vh - 50px);
        background: rgba(28, 44, 56, 0.99);
        top: 50px;
        left: -100%;
        transition: .5s;
    }
    header nav.active
    {
        left: 0;
    }
    header nav ul
    {
        display: block;
        /*text-align: center;*/
    }
    header nav ul li a
    {
        border-bottom: 1px solid rgba(255, 255, 255, .5);
        height: 50px;
        line-height: 50px;
        padding: 0 20px;
    }
    header nav ul li.active ul
    {
        position: relative;
    }
    header nav ul li ul li
    {
        width: 100%;
    }

    /* new: header nav ul li.sub-menu */
    /* why: so that dropdown menus fill the entire row in mobile */
    header nav ul li.sub-menu
    {
        padding: 8.5px 0;
    }

    header nav ul li.sub-menu:before
    {
        content: '+'; /* old: &#9660 nabla */
        font-size: 20pt;
        font-family: sans-serif;
        position: absolute;
        line-height: 30px;
        color: #ffffff;
        top: 5pt;
        right: 25px;
        cursor: pointer;
    }
    header nav ul li.active.sub-menu:before
    {
        content: '-';  /* new: &#9650 Delta */
        font-size: 30pt;
        top: 5pt;
        right: 25px;
        line-height: 30px;
        cursor: pointer;
    }
    header nav ul li ul
    {
        position: absolute;
        left: 0;
        top: 0px; /* controls the box position of 2018 and 2019 under Research materials */
        background: rgba(57, 143, 209, 0.99);
        display: none;
    }

    /* new: hover and active
    why: do not display drop down menus when mouse is over it
    and looking in mobile, but display them when plus signs are clicked */
    header nav ul li:hover ul
    {
        display: none;
    }
    header nav ul li.active ul
    {
        display: block;
    }

    /* new: News; why: to make News align with the others in mobile */
    /* commented out since Research Materials uses different method
    to get more space on its right (header nav ul li.sub-menu padding) */

    /* header nav ul li.news
    {
        margin: 0;
    } */
    /* new: rm; why: to make rm align with the others in mobile */
    /* commented out for the same reason */
    /* header nav ul li#rm
    {
        margin: 0;
    } */

    /* while scrolling */

}

/* while scrolling */
header.black
{
    background: rgba(21, 92, 148, .7);
}
</style>

<!-- 1. Navigation bar color change as one scrolls -->
<!-- by adding a new class="black" while scrolling -->
<script src="https://code.jquery.com/jquery-3.3.1.js"></script>
<script type="text/javascript">
    $(window).on('scroll', function(){
        if ($(window).scrollTop()){
            $('header').addClass('black');
        }
        else
        {
            $('header').removeClass('black');
        }
    })
</script>

<!-- 2. Navigation bar slides from the left in mobile -->
<!-- 3. Only one dropdown menu at a time will appear -->
<script type="text/javascript">
    $(document).ready(function(){
        $('.menu-toggle').click(function(){
            $('nav').toggleClass('active')
        })
        $('ul li').click(function(){
            $(this).siblings().removeClass('active');
            $(this).toggleClass('active');
        })
    })
</script>

<!-- Using caret down and up symbols -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
<link rel="icon" href="../../style/all_orange_jp.png">


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link rel="stylesheet" href="non_separable_penalty_files/style.css" type="text/css" />

</head>

<body>


<!-- A new navigation bar -->
<header>
    <div class="logo">
        <a href="../../index.html"><img src="../../style/all_orange_jp.png"></a>
    </div>
    <nav>
        <ul>
            <li>
                <a href="../../cv.html">About</a>
            </li>
            <li class="sub-menu" id="projects">
                <a href="../../projects.html">Projects</a>
                <ul>
                    <li>
                        <a href="../../projects/2019.html">2019</a>
                    </li>
                </ul>
            </li>
            <li class="sub-menu" id="rm">
                <a href="../../research_materials.html">Research materials</a>
                <ul>
                    <li>
                        <a href="../../research_materials/2018.html">2018</a>
                    </li>
                    <li>
                        <a href="../../research_materials/2019.html">2019</a>
                    </li>
                </ul>
            </li>
            <li id="news">
                <a href="../../news.html">News</a>
            </li>
        </ul>
    </nav>
    <div class="menu-toggle">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
</header>


<section class="page-header">
<h1 class="title toc-ignore project-name">Dealing with a non-separable penalty</h1>
<h4 class="author project-author">Junkyu Park</h4>
</section>


<div id="TOC" class="toc">
<ul>
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#the-problem">2. The problem</a><ul>
<li><a href="#the-model">The model</a></li>
<li><a href="#change-of-variables">Change of variables</a></li>
<li><a href="#the-minimizers">The minimizers</a></li>
</ul></li>
<li><a href="#an-example">3. An example</a><ul>
<li><a href="#the-data">The data</a></li>
<li><a href="#choosing-lambda">Choosing <span class="math inline">\(\lambda\)</span></a></li>
<li><a href="#python-implementation">Python implementation</a></li>
</ul></li>
<li><a href="#session-info">Session Info</a></li>
</ul>
</div>

<section class="main-content">
<p>The following link is pointing towards this document:</p>
<ul>
<li><a href="../2019/cross_validation_fs.html">Cross-validation for fusion estimates</a></li>
</ul>
<p>The following external R packages/functions are used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
gather &lt;-<span class="st"> </span>tidyr<span class="op">::</span>gather
pmap &lt;-<span class="st"> </span>purrr<span class="op">::</span>pmap</code></pre></div>
<p>and the following Python modules are used:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> datetime <span class="im">import</span> datetime <span class="im">as</span> dt
<span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt
<span class="im">import</span> numpy <span class="im">as</span> np</code></pre></div>
<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<p>This note concerns with finding a “signal” in data using a non-separable penalty and coordinate descent. With a very simple model, it will introduce a cost function having a non-separable penalty on parameters to estimate true signals. Also, it will demonstrate that we can use a coordinate descent algorithm with a simple change of variables, albeit non-separable.</p>
</div>
<div id="the-problem" class="section level1">
<h1>2. The problem</h1>
<div id="the-model" class="section level2">
<h2>The model</h2>
<p>Consider observations <span class="math inline">\(y_1, \dots, y_n \in \mathbb{R}\)</span> which we may believe have the following form: <span class="math display">\[y_t = \theta_t + \varepsilon_t\]</span> where <span class="math inline">\(\varepsilon_t \stackrel{iid}{\sim} N(0, \sigma^2)\)</span> is a white noise. That is, we believe that each data point (<span class="math inline">\(y_t\)</span>’s) consists of the true “signal” (<span class="math inline">\(\theta_t\)</span>’s) and the noise term (<span class="math inline">\(\varepsilon_t\)</span>’s). Our primary objective is to interpolate, i.e. to find <span class="math inline">\(\theta_t\)</span>’s at each <span class="math inline">\(t\)</span>.</p>
<p>Say the cost function we want to minimize is: <span class="math display">\[\text{cost}_1(\theta_1, \dots, \theta_n) := \sum_{t = 1}^{n} (y_t - \theta_t)^2\]</span> This leads to conclude that the minimizers of this cost function are: <span class="math display">\[\hat{\theta}_t = y_t\]</span> for all <span class="math inline">\(t\)</span>. But this is boring; we don’t want to conclude that <span class="math inline">\(P(\varepsilon_t = 0) = 1\)</span> for all <span class="math inline">\(t\)</span>. What we want is to extract and separate the truth from the noise using given data points and an appropriate cost function.</p>
<p>Let’s assume <span class="math inline">\(\theta_t\)</span>’s are “smooth in general”, i.e. <span class="math inline">\(|\theta_t - \theta_{t - 1}|\)</span> are small for “most” values of <span class="math inline">\(t\)</span>. That is, for some <span class="math inline">\(s\)</span> and <span class="math inline">\(s + 1\)</span>, we may have a sudden change between <span class="math inline">\(\theta_s\)</span> and <span class="math inline">\(\theta_{s + 1}\)</span> so that <span class="math inline">\(y_s\)</span> and <span class="math inline">\(y_{s + 1}\)</span> may exhibit a “jump”. The assumption suggests us to include a penalty term in our cost function to penalize the lack of smoothness. The cost function that incorporates our need is: <span class="math display">\[\text{cost}(\theta_1, \dots, \theta_n) := \sum_{t = 1}^{n} (y_t - \theta_t)^2 + \lambda \sum_{t = 2}^{n} |\theta_t - \theta_{t - 1}|\]</span> where <span class="math inline">\(\lambda\)</span> is a tuning parameter just like in LASSO or ridge regression.</p>
</div>
<div id="change-of-variables" class="section level2">
<h2>Change of variables</h2>
<p>Clearly, the penalty term <span class="math inline">\(\sum_{t = 2}^{n} |\theta_t - \theta_{t - 1}|\)</span> is not separable. However, inspired from LASSO, we can turn this into a separable penalty. Namely: <span class="math display">\[\phi_t := \theta_t - \theta_{t - 1}\]</span> for <span class="math inline">\(t = 2, \dots, n\)</span>. For a complete description, we may define <span class="math inline">\(\phi_1 := 0\)</span>. Then the cost function becomes: <span class="math display">\[\text{cost} = \sum_{t = 1}^{n} (y_t - \theta_t)^2 + \lambda \sum_{t = 1}^{n} |\phi_t|\]</span> This separable form suggests us that we can use coordinate descent to find <span class="math inline">\(\hat{\phi}_t\)</span>’s iteratively, and thereby <span class="math inline">\(\hat{\theta}_t\)</span>’s.</p>
<p>Using induction, we can conclude that <span class="math inline">\(\theta_t = \theta_1 + \sum_{s = 2}^{t} \phi_s\)</span> for <span class="math inline">\(t \geq 2\)</span>. That is, the cost can be written as a function of <span class="math inline">\(\theta_1, \phi_1 ( = 0), \phi_2, \dots, \phi_n\)</span>, or: <span class="math display">\[\text{cost}(\theta_1, \phi_1 = 0, \phi_2, \dots, \phi_n) = \sum_{t = 1}^{n} (y_t - \theta_t)^2 + \lambda \sum_{t = 1}^{n} |\phi_t|\]</span> or simply: <span class="math display">\[\text{cost}(\theta_1, \phi_2, \dots, \phi_n) = \sum_{t = 1}^{n} (y_t - \theta_t)^2 + \lambda \sum_{t = 2}^{n} |\phi_t|\]</span></p>
<p>Minimizers of this sort of cost function are called fusion estimates.</p>
</div>
<div id="the-minimizers" class="section level2">
<h2>The minimizers</h2>
<p>The fact that cost function is separable allows us to consider the other parameters being fixed and only one parameter being a variable so that we can minimize the cost “one by one”.</p>
<p>First, let <span class="math inline">\(\phi_2, \dots, \phi_n\)</span> be fixed and <span class="math inline">\(\theta_1\)</span> be a variable. Then in the cost function, <span class="math inline">\(\lambda \sum_{t = 2}^{n} |\phi_t|\)</span> becomes a constant, so it becomes equivalent to minimizing <span class="math inline">\(\sum_{t = 1}^{n} (y_t - \theta_t)^2\)</span>. Notice that this is a convex quadratic function of <span class="math inline">\(\theta_1\)</span>:</p>
<span class="math display">\[\begin{align*}
\sum_{t = 1}^{n}(y_t - \theta_t)^2 &amp;= (y_1 - \theta_1)^2 + \sum_{t = 2}^{n}\big(y_t - \theta_1 - \sum_{s = 2}^{t} \phi_s \big)^2 \\
&amp;= (\theta_1 - y_1)^2 + \sum_{t = 2}^{n} \Big[ \theta_1 - \big( y_t - \sum_{s = 2}^{t} \phi_s \big) \Big]^2 \\
&amp;= (\theta_1 - y_1)^2 + \sum_{t = 2}^{n} \Big[ \theta_1^2 - 2 \theta_1 \big(y_t - \sum_{s = 2}^{t} \phi_s \big) + \big(y_t - \sum_{s = 2}^{t} \phi_s \big)^2  \Big] \\
&amp;= n \theta_1^2 - 2 \theta_1 \Big[ y_1 + \sum_{t = 2}^{n} \big( y_t - \sum_{s = 2}^{t} \phi_s \big) \Big] + \text{constant}(\mathbf{y}, \phi_2, \dots, \phi_n)
\end{align*}\]</span>
<p>So the critical value <span class="math inline">\(\theta_1^*\)</span> that minimizes the above is computed as:</p>
<span class="math display">\[\begin{align*}
\frac{\partial}{\partial \theta_1} \sum_{t = 1}^{n}(y_t - \theta_t)^2 \Big|_{\theta_1 = \theta_1^*} &amp;= 2n \theta_1^* - 2 \Big[ y_1 + \sum_{t = 2}^{n} \big( y_t - \sum_{s = 2}^{t} \phi_s \big) \Big] = 0\\
\implies \therefore \theta_1^* &amp;= \frac{1}{n} \Big[ y_1 + \sum_{t = 2}^{n} \big( y_t - \sum_{s = 2}^{t} \phi_s \big) \Big]
\end{align*}\]</span>
<p>Now, consider <span class="math inline">\(\theta_1, \phi_2, \dots , \phi_{j - 1}, \phi_{j + 1}, \dots, \phi_n\)</span> are fixed and <span class="math inline">\(\phi_j\)</span> is a variable (<span class="math inline">\(j = 2, \dots, n\)</span>). Then the first term of the cost function can be written as:</p>
<span class="math display">\[\begin{align*}
\sum_{t = 1}^{n} (y_t - \theta_t)^2 &amp;= \underbrace{\phi_1}_{=0} + (y_1 - \theta_1)^2 + \underbrace{\sum_{t &lt; j} \big( y_t - \theta_1 - \sum_{s = 2}^{t} \phi_s \big)^2}_{:= \text{ } 0 \text{ if } j = 2} + \sum_{t \geq j} \big( y_t - \theta_1 - \sum_{s = 2}^{t} \phi_s \big)^2 \\
&amp;= \underbrace{\underset{1 \leq t \leq j - 1}{\text{constant}}(y_{t}, \theta_1, \phi_{t})}_{= \text{ constant1}} + \sum_{t = j}^{n} \big( y_t - \theta_1 - \sum_{s = 2}^{t} \phi_s \big)^2 \\
&amp;= \text{constant1} + \sum_{t = j}^{n} \big(\phi_j - y_t + \theta_1 + \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big)^2 \\
&amp;= \text{constant1} + \sum_{t = j}^{n} \Big[\phi_j^2 - 2 \phi_j \big( y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big) + \text{constant2} \Big] \\
&amp;= \sum_{t = j}^{n} \Big[\phi_j^2 - 2 \phi_j \big( y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big) \Big] + \text{constant} \\
&amp;= (n - j + 1)\phi_j^2 - 2 \phi_j \sum_{t = j}^{n} \Big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \Big] + \text{constant}
\end{align*}\]</span>
<p>Differentiate this with respect to <span class="math inline">\(\phi_j\)</span> and obtain the derivative:</p>
<p><span class="math display">\[\frac{\partial}{\partial \phi_j} \sum_{t = 1}^{n}(y_t - \theta_i)^2 = 2(n - j + 1)\phi_j - 2 \sum_{t = j}^{n} \Big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \Big]\]</span></p>
<p>which is also the subgradient. Now the second term <span class="math inline">\(\lambda \sum_{t = 2}^{n} |\phi_t|\)</span> is easy: <span class="math display">\[\lambda \sum_{t = 2}^{n} |\phi_t| = \lambda \Big( |\phi_j| + \sum_{t \neq j} |\phi_t| \Big) = \lambda|\phi_j| + \text{constant}\]</span></p>
<p>Since subgradients are linear, the subgradient with respect to <span class="math inline">\(\phi_j\)</span> is <span class="math inline">\(\lambda \partial|\phi_j|\)</span> where <span class="math display">\[\partial |\phi_j| = \begin{cases} -1 \hspace{20pt} \text{ if } \phi_j &lt; 0 \\ [-1, 1] \hspace{4pt} \text{ if } \phi_j = 0 \\ 1 \hspace{27pt} \text{ if } \phi_j &gt; 0 \end{cases}\]</span></p>
<p>so the cost function’s subgradient <span class="math inline">\(\partial \text{cost}(\phi_j)\)</span> is then: <span class="math display">\[\partial \text{cost}(\phi_j) := 2(n - j + 1)\phi_j - 2 \sum_{t = j}^{n} \Big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \Big] + \lambda \partial|\phi_j|\]</span></p>
<p>Suppose <span class="math inline">\(\phi_j^*\)</span> is the value that minimizes <span class="math inline">\(\text{cost}(\phi_j)\)</span>. <span class="math inline">\(\phi_j^* \neq 0\)</span> if and only if:</p>
<span class="math display">\[\begin{align*}
&amp;2(n - j + 1)\phi_j^* - 2 \sum_{t = j}^{n} \Big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \Big] + \lambda \partial|\phi_j^*| = 0 \\
\iff &amp;\begin{cases} (n - j + 1)\phi_j^* -  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] - \frac{\lambda}{2} = 0 \text{ given } \phi_j^* &lt; 0 \\ (n - j + 1)\phi_j^* -  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] + \frac{\lambda}{2} = 0 \text{ given } \phi_j^* &gt; 0 \end{cases} \\
\iff &amp;\hspace{4pt} \phi_j^* = \begin{cases} (n - j + 1)^{-1} \Big[ \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] + \frac{\lambda}{2} \Big] \text{ given } \phi_j^* &lt; 0 \\ (n - j + 1)^{-1} \Big[ \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] - \frac{\lambda}{2} \Big] \text{ given } \phi_j^* &gt; 0 \end{cases}
\end{align*}\]</span>
<p>Since <span class="math inline">\((n - j + 1)^{-1} &gt; 0\)</span>, the following is required to satisfy each given condition:</p>
<span class="math display">\[\begin{align*}
\phi_j^* \begin{cases} &lt; 0 \text{ if }  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] + \frac{\lambda}{2} &lt; 0 \\ &gt; 0 \text{ if }  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] - \frac{\lambda}{2} &gt; 0 \end{cases}
\end{align*}\]</span>
<p>Combine these to obtain the non-zero minimizer <span class="math inline">\(\phi_j^*\)</span>: <span class="math display">\[\phi_j^* = \begin{cases} (n - j + 1)^{-1} \Big[ \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] + \frac{\lambda}{2} \Big] \text{ if }  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] &lt; - \frac{\lambda}{2} \\ (n - j + 1)^{-1} \Big[ \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] - \frac{\lambda}{2} \Big] \text{ if }  \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] &gt; \frac{\lambda}{2} \end{cases}\]</span></p>
<p>Finally, the minimizer <span class="math inline">\(\phi_j^*\)</span> is <span class="math inline">\(0\)</span> if <span class="math inline">\(- 2\sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] + \lambda[-1, 1] \ni 0\)</span></p>
<span class="math display">\[\begin{align*}
&amp;\iff -\lambda - 2\sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] \leq 0 \leq \lambda - 2\sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] \\
&amp;\iff \Big| \sum_{t = j}^{n} \big[ y_t - \theta_1 - \sum_{\underset{s \neq j}{s = 2}}^{t} \phi_s \big] \Big| \leq \frac{\lambda}{2}
\end{align*}\]</span>
<p>The coordinate descent algorithm is applied as follows:</p>
<ol style="list-style-type: decimal">
<li>Start with <span class="math inline">\(\boldsymbol{\theta}^{(0)} = (\theta_1^{(0)}, \dots, \theta_n^{(0)})\)</span>.</li>
<li>At iteration <span class="math inline">\(\ell\)</span>, compute <span class="math inline">\(\boldsymbol{\phi}^{(\ell)} = (\phi_1^{(\ell)}, \phi_2^{(\ell)}, \dots, \phi_n^{(\ell)})\)</span> from <span class="math inline">\(\boldsymbol{\theta}^{(\ell)}\)</span> as:</li>
</ol>
<span class="math display">\[\begin{align*}
\phi_1^{(\ell)} &amp;= 0 \text{ for all } \ell \\
\phi_t^{(\ell)} &amp;= \theta_t^{(\ell)} - \theta_{t - 1}^{(\ell)} \text{ for } t \in \{2, \dots, n \}
\end{align*}\]</span>
<ol start="3" style="list-style-type: decimal">
<li>Compute <span class="math inline">\(\text{cost}^{(\ell)} := \text{cost}(\theta_1^{(\ell)}, \phi_2^{(\ell)}, \dots, \phi_n^{(\ell)})\)</span>; if <span class="math inline">\(\ell \geq 1\)</span>, compute <span class="math inline">\(|\text{cost}^{(\ell)} - \text{cost}^{(\ell - 1)}|\)</span> also.</li>
<li>Compute the minimizers of <span class="math inline">\(\text{cost}(\theta_1, \phi_2, \dots, \phi_n)\)</span> sequentially:</li>
</ol>
<span class="math display">\[\begin{align*}
\theta_1^{(\ell + 1)} &amp;= \frac{1}{n} \Big[ y_1 + \sum_{t = 2}^{n}\big(y_t - \sum_{s = 2}^{t} \phi_s^{(\ell)} \big) \Big] \\
\phi_j^{(\ell + 1)} &amp;= \underset{\phi_j}{\text{argmin}} \Big( \text{cost}(\theta_1^{(\ell + 1)}, \phi_2^{(\ell + 1)}, \dots, \phi_{j - 1}^{(\ell + 1)}, \phi_j, \phi_{j + 1}^{(\ell)}, \dots, \phi_n^{(\ell)}) \Big) \text{ } \forall \text{ } j \geq 2
\end{align*}\]</span>
<ol start="5" style="list-style-type: decimal">
<li>Compute <span class="math inline">\(\boldsymbol{\theta}^{(\ell + 1)} = (\theta_1^{(\ell + 1)}, \theta_2^{(\ell + 1)}, \dots, \theta_n^{(\ell + 1)})\)</span> as: <span class="math display">\[\theta_t^{(\ell + 1)} = \theta_1^{(\ell + 1)} + \sum_{s = 2}^{t} \phi_s^{(\ell + 1)}\]</span> for <span class="math inline">\(t \geq 2\)</span>.</li>
<li>Repeat from step 2 to 5 until <span class="math inline">\(|\text{cost}^{(\ell + 1)} - \text{cost}^{(\ell)}|\)</span> is no longer greater than some predefined threshold.</li>
</ol>
</div>
</div>
<div id="an-example" class="section level1">
<h1>3. An example</h1>
<div id="the-data" class="section level2">
<h2>The data</h2>
<p>Suppose <span class="math inline">\(n = 1000\)</span>, and: <span class="math display">\[\theta_t = \begin{cases} 0 &amp; 1 \leq t \leq 249 \\ f(t) = \frac{t}{250} - .5 &amp; 250 \leq t \leq 500 \\ .75 &amp; 501 \leq t \leq 550 \\ g(t) = -\frac{.25}{449}t + \frac{250}{449} &amp; 551 \leq t \leq 1000 \end{cases}\]</span> With the following white noise <span class="math inline">\(\varepsilon_t \stackrel{iid}{\sim} N(0, \sigma^2 = .1)\)</span>, let’s generate the data <code>y</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1024</span>)
n &lt;-<span class="st"> </span><span class="dv">1000</span>
t &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>n
f &lt;-<span class="st"> </span><span class="cf">function</span>(t) {t <span class="op">/</span><span class="st"> </span><span class="dv">250</span> <span class="op">-</span><span class="st"> </span>.<span class="dv">5</span>}
g &lt;-<span class="st"> </span><span class="cf">function</span>(t) {<span class="op">-</span>(.<span class="dv">25</span> <span class="op">/</span><span class="st"> </span><span class="dv">449</span>) <span class="op">*</span><span class="st"> </span>t <span class="op">+</span><span class="st"> </span><span class="dv">250</span> <span class="op">/</span><span class="st"> </span><span class="dv">449</span>}
true_theta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">249</span>), <span class="kw">f</span>(<span class="dv">250</span><span class="op">:</span><span class="dv">500</span>), <span class="kw">rep</span>(.<span class="dv">75</span>, <span class="dv">50</span>), <span class="kw">g</span>(<span class="dv">551</span><span class="op">:</span><span class="dv">1000</span>))
y &lt;-<span class="st"> </span>true_theta <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)
<span class="kw">qplot</span>(t, y)</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/following_data-1.png" style="display: block; margin: auto;" /></p>
<p>The function <code>fusion_estimates</code> implements the algorithm described above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fusion_estimates &lt;-<span class="st"> </span><span class="cf">function</span>(y, theta, lambda, <span class="dt">max_iter =</span> <span class="dv">100</span>, <span class="dt">eps =</span> <span class="fl">1e-5</span>) {
    n &lt;-<span class="st"> </span><span class="kw">length</span>(y)
    <span class="cf">if</span> (<span class="kw">missing</span>(theta)) {theta &lt;-<span class="st"> </span>y}
    <span class="cf">if</span> (<span class="kw">length</span>(theta) <span class="op">!=</span><span class="st"> </span>n) {
        <span class="kw">stop</span>(<span class="kw">paste0</span>(
            <span class="st">&#39;</span><span class="ch">\n</span><span class="st">Error in fusion_estimates():</span><span class="ch">\n</span><span class="st">&#39;</span>, 
            <span class="st">&#39;The length of given initial theta is &#39;</span>, <span class="kw">length</span>(theta),
            <span class="st">&#39;, which is not equal to length(y) == &#39;</span>, n, <span class="st">&#39;.&#39;</span>
        ))
    }
    phi &lt;-<span class="st"> </span><span class="kw">diff</span>(theta)
    phisums_old &lt;-<span class="st"> </span><span class="kw">cumsum</span>(phi)
    theta_1_new &lt;-<span class="st"> </span>(<span class="kw">sum</span>(y) <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(phisums_old)) <span class="op">/</span><span class="st"> </span>n
    cost &lt;-<span class="st"> </span><span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(phi))
    costs &lt;-<span class="st"> </span><span class="ot">NULL</span>
    costs[<span class="dv">1</span>] &lt;-<span class="st"> </span>cost <span class="co"># costs</span>
    there_is_a_progress &lt;-<span class="st"> </span>T
    iter &lt;-<span class="st"> </span><span class="dv">0</span>
    <span class="cf">while</span> (there_is_a_progress <span class="op">&amp;</span><span class="st"> </span>iter <span class="op">&lt;</span><span class="st"> </span>max_iter) {
        <span class="co"># Store new phi_1 (= 0) to phi_n in phi_new</span>
        phi_new &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dt">length =</span> n) 
        <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n) {
            phisums_new &lt;-<span class="st"> </span><span class="kw">cumsum</span>(phi_new)
            req &lt;-<span class="st"> </span><span class="kw">sum</span>(
                phisums_old[(j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)] <span class="op">-</span><span class="st"> </span>
<span class="st">                </span>phisums_old[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>phisums_new[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>]
            )
            discri &lt;-<span class="st"> </span><span class="kw">sum</span>(y[j<span class="op">:</span>n]) <span class="op">-</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>theta_1_new <span class="op">-</span><span class="st"> </span>req
            <span class="cf">if</span> (discri <span class="op">&lt;</span><span class="st"> </span><span class="op">-</span>lambda <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) {
                phi_new[j] &lt;-<span class="st"> </span>(discri <span class="op">+</span><span class="st"> </span>lambda <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)
            } <span class="cf">else</span> <span class="cf">if</span> (discri <span class="op">&gt;</span><span class="st"> </span>lambda <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) {
                phi_new[j] &lt;-<span class="st"> </span>(discri <span class="op">-</span><span class="st"> </span>lambda <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)
            } <span class="co"># already 0 otherwise</span>
        }
        phi_new &lt;-<span class="st"> </span>phi_new[<span class="op">-</span><span class="dv">1</span>]
        phisums_new &lt;-<span class="st"> </span>phisums_new[<span class="op">-</span><span class="dv">1</span>]
        theta &lt;-<span class="st"> </span><span class="kw">c</span>(theta_1_new, theta_1_new <span class="op">+</span><span class="st"> </span>phisums_new)
        cost &lt;-<span class="st"> </span><span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(phi_new))
        theta_1_new &lt;-<span class="st"> </span>(<span class="kw">sum</span>(y) <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(phisums_new)) <span class="op">/</span><span class="st"> </span>n
        phisums_old &lt;-<span class="st"> </span>phisums_new
        iter &lt;-<span class="st"> </span>iter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
        costs[iter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> </span>cost
        there_is_a_progress &lt;-<span class="st"> </span><span class="op">!</span>(<span class="kw">abs</span>(costs[iter] <span class="op">-</span><span class="st"> </span>cost) <span class="op">&lt;=</span><span class="st"> </span>eps)
    }
    <span class="kw">list</span>(
        <span class="dt">theta =</span> theta, 
        <span class="dt">phi =</span> phi_new, 
        <span class="dt">lambda =</span> lambda, 
        <span class="dt">iter =</span> iter, 
        <span class="dt">costs =</span> costs <span class="co"># the first cost is calculated at iteration 0</span>
    )
}</code></pre></div>
<p>First, let’s see if the cost function monotonically decreases as we iterate. We start with:</p>
<ul>
<li><span class="math inline">\(\theta^{(0)} = .5 \times \mathbf{1}_{n \times 1}\)</span></li>
<li><span class="math inline">\(\lambda = 1\)</span></li>
<li>Maximum iteration of 1000</li>
</ul>
<p>These choices are arbitrary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Start &lt;-<span class="st"> </span><span class="kw">rep</span>(.<span class="dv">5</span>, n)
start_r &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()
example1 &lt;-<span class="st"> </span><span class="kw">fusion_estimates</span>(y, <span class="dt">theta =</span> Start, <span class="dt">lambda =</span> <span class="dv">1</span>, <span class="dt">max_iter =</span> <span class="dv">1000</span>)
end_r &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()
<span class="kw">qplot</span>(
    <span class="kw">seq_along</span>(example1<span class="op">$</span>costs) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, example1<span class="op">$</span>costs, 
    <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>,
    <span class="dt">xlab =</span> <span class="st">&#39;Iteration&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;Cost function&#39;</span>
)</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/example1_work-1.png" style="display: block; margin: auto;" /></p>
<p>It does <em>monotonically</em> decrease, indicating the convergence of the <span class="math inline">\(\text{cost}\)</span> by the monotone convergence theorem (since <span class="math inline">\(\text{cost}\)</span> is non-negative). This is how the estimated <code>theta</code> of <code>example1</code> looks like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(t, y, Start, <span class="st">`</span><span class="dt">Estimated theta</span><span class="st">`</span> =<span class="st"> </span>example1<span class="op">$</span>theta) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">gather</span>(Type, value, <span class="op">-</span>(t<span class="op">:</span>y)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Type =</span> <span class="kw">factor</span>(Type, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&#39;Start&#39;</span>, <span class="st">&#39;Estimated theta&#39;</span>))) <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> t)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> y), <span class="dt">pch =</span> <span class="dv">21</span>, <span class="dt">alpha =</span> .<span class="dv">25</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">col =</span> Type)) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_colour_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&#39;#56B4E9&#39;</span>, <span class="st">&#39;black&#39;</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">col =</span> <span class="st">&#39;&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(
        <span class="dt">legend.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&#39;transparent&#39;</span>),
        <span class="dt">legend.position =</span> <span class="kw">c</span>(.<span class="dv">845</span>, .<span class="dv">895</span>)
    )</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/how_it_looks_like-1.png" style="display: block; margin: auto;" /></p>
<p>The estimated theta is not so smooth since <span class="math inline">\(\lambda = 1\)</span> is quite small.</p>
<p>Perhaps the relationship between <span class="math inline">\(\lambda\)</span> and the smoothness of signals is the one we want to look at. With the same <code>max_iter</code> (<code>100</code>) and <code>theta</code> (<code>rep(mean(y), n)</code>), we shall try different values of <code>lambda</code> and see how <code>theta</code> is computed for each <code>lambda</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pmap</span>(
    <span class="kw">list</span>(<span class="dt">lambda =</span> <span class="kw">list</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>)),
    fusion_estimates, 
    <span class="dt">y =</span> y, <span class="dt">theta =</span> <span class="kw">rep</span>(<span class="kw">mean</span>(y), n)
) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">sapply</span>(<span class="cf">function</span>(d){d<span class="op">$</span>theta}) <span class="op">%&gt;%</span>
<span class="st">    &#39;colnames&lt;-&#39;</span>(<span class="kw">c</span>(<span class="st">&#39;5&#39;</span>, <span class="st">&#39;10&#39;</span>, <span class="st">&#39;20&#39;</span>, <span class="st">&#39;50&#39;</span>, <span class="st">&#39;100&#39;</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">cbind</span>(<span class="kw">tibble</span>(<span class="dt">t =</span> t, <span class="dt">y =</span> y)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">gather</span>(lambda, value, <span class="op">-</span>(t<span class="op">:</span>y)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(
        <span class="dt">lambda =</span> <span class="kw">factor</span>(lambda, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&#39;5&#39;</span>, <span class="st">&#39;10&#39;</span>, <span class="st">&#39;20&#39;</span>, <span class="st">&#39;50&#39;</span>, <span class="st">&#39;100&#39;</span>))
    ) <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> t, <span class="dt">y =</span> y, <span class="dt">col =</span> lambda)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">pch =</span> <span class="dv">21</span>, <span class="dt">alpha =</span> .<span class="dv">1</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/rel1_plot-1.png" style="display: block; margin: auto;" /></p>
<p>The plot reveals that as <code>lambda</code> gets bigger, <code>theta</code> converges to <code>mean(y)</code>. This makes sense because a large enough <code>lambda</code> will make all of <span class="math inline">\(\phi_j^*\)</span>’s to be exactly <span class="math inline">\(0\)</span>, and all of <span class="math inline">\(\theta_t\)</span>’s will be equal to <span class="math inline">\(\theta_1 = \frac{1}{n}\sum_{t = 1}^{n}y_t\)</span>. So in a sense, <code>theta</code> becomes smooth as <code>lambda</code> increases; it gets very smooth that it becomes a constant (<code>mean(y)</code>).</p>
<p>Below are plots having <code>max_iter = 5000</code>, <code>theta = y</code> (which is the default of <code>fusion_estimates</code> if <code>theta</code> is not specified), and <code>lambda</code> equal to <code>.1</code>, <code>1</code>, <code>10</code>, <code>100</code>, and <code>1000</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pmap</span>(
    <span class="kw">list</span>(<span class="dt">lambda =</span> <span class="kw">list</span>(.<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>)),
    fusion_estimates, <span class="dt">y =</span> y, <span class="dt">max_iter =</span> <span class="dv">5000</span>
) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">sapply</span>(<span class="cf">function</span>(d){d<span class="op">$</span>theta}) <span class="op">%&gt;%</span>
<span class="st">    &#39;colnames&lt;-&#39;</span>(<span class="kw">c</span>(
        <span class="st">&#39;lambda = 0.1&#39;</span>, <span class="st">&#39;lambda = 1&#39;</span>, <span class="st">&#39;lambda = 10&#39;</span>, 
        <span class="st">&#39;lambda = 100&#39;</span>, <span class="st">&#39;lambda = 1000&#39;</span>
    )) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">cbind</span>(<span class="kw">tibble</span>(<span class="dt">t =</span> t, <span class="dt">y =</span> y)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">gather</span>(lambda, value, <span class="op">-</span>(t<span class="op">:</span>y)) <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> t, <span class="dt">y =</span> y, <span class="dt">col =</span> lambda)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">pch =</span> <span class="dv">21</span>, <span class="dt">alpha =</span> .<span class="dv">05</span>, <span class="dt">col =</span> <span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value), <span class="dt">size =</span> .<span class="dv">25</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(lambda <span class="op">~</span><span class="st"> </span>., <span class="dt">ncol =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;none&#39;</span>)</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/rel2_plot-1.png" style="display: block; margin: auto;" /></p>
<p>There are two finding from these plots: one finding is that <code>theta</code> is essentially a piecewise constant function (or an approximation by a step function), and the other is that up until a certain point, a bigger <code>lambda</code> leads to a “smoother” <code>theta</code> within a “reasonable range of data” (see the case of <code>lambda = 0.1</code> and <code>lambda = 1</code>). But if <code>lambda</code> gets bigger than that certain point, then smoothness of <code>theta</code> does not help us finding a true signal from <code>y</code>.</p>
</div>
<div id="choosing-lambda" class="section level2">
<h2>Choosing <span class="math inline">\(\lambda\)</span></h2>
<p>See <a href="../2019/cross_validation_fs.html">here</a> for details.</p>
</div>
<div id="python-implementation" class="section level2">
<h2>Python implementation</h2>
<p>Here’s an equivalent Python-version of <code>fusion_estimates</code>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> fusion_estimates(y, lambd, theta <span class="op">=</span> <span class="va">None</span>, max_iter <span class="op">=</span> <span class="dv">1000</span>, eps <span class="op">=</span> <span class="fl">1e-05</span>):
    <span class="co">&#39;&#39;&#39;(np.array, number[, np.array, int, number]) -&gt; </span>
<span class="co">        {str: np.array or number}</span>
<span class="co">    </span>
<span class="co">    Preconditions:</span>
<span class="co">    1. len(y) == len(theta) if theta specified.</span>
<span class="co">    2. lambd &gt; 0 and eps &gt; 0</span>
<span class="co">    3. max_iter &gt; 1</span>

<span class="co">    Return the dictionary that stores: </span>
<span class="co">    - &#39;theta&#39;, the fusion estimates of y iterated from theta with the</span>
<span class="co">      maximum iteration max_iter and the cost difference threshold eps.</span>
<span class="co">    - &#39;phi&#39;, the differences of each &#39;theta&#39;</span>
<span class="co">    - &#39;lambd&#39;, the lambd specified</span>
<span class="co">    - &#39;iteration&#39;, the number of iterations, and</span>
<span class="co">    - &#39;costs&#39;, the cost function evaluated at each iteration where the</span>
<span class="co">      first cost is calculated at iteration 0.</span>
<span class="co">    &#39;&#39;&#39;</span>
    
    n <span class="op">=</span> <span class="bu">len</span>(y)
    <span class="cf">if</span> theta <span class="kw">is</span> <span class="va">None</span>:
        theta <span class="op">=</span> y.copy()
    phi <span class="op">=</span> np.diff(theta)
    phisums_old <span class="op">=</span> np.cumsum(phi)
    theta_1_new <span class="op">=</span> (<span class="bu">sum</span>(y) <span class="op">-</span> <span class="bu">sum</span>(phisums_old)) <span class="op">/</span> n
    cost <span class="op">=</span> <span class="bu">sum</span>((y <span class="op">-</span> theta) <span class="op">**</span> <span class="dv">2</span>) <span class="op">+</span> lambd <span class="op">*</span> <span class="bu">sum</span>(<span class="bu">abs</span>(phi))
    costs <span class="op">=</span> []
    costs.append(cost)
    there_is_a_progress <span class="op">=</span> <span class="va">True</span>
    iteration <span class="op">=</span> <span class="dv">0</span>
    <span class="cf">while</span> there_is_a_progress <span class="kw">and</span> iteration <span class="op">&lt;</span> max_iter:
        phi_new <span class="op">=</span> np.zeros(n)
        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):
            phisums_new <span class="op">=</span> np.cumsum(phi_new)
            req <span class="op">=</span> <span class="bu">sum</span>(
                phisums_old[(j <span class="op">-</span> <span class="dv">1</span>):(n <span class="op">-</span> <span class="dv">1</span>)] <span class="op">-\</span>
                phisums_old[j <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> phisums_new[j <span class="op">-</span> <span class="dv">1</span>]
            )
            discri <span class="op">=</span> <span class="bu">sum</span>(y[j:n]) <span class="op">-</span> (n <span class="op">-</span> (j <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> theta_1_new <span class="op">-</span> req
            <span class="cf">if</span> discri <span class="op">&lt;</span> <span class="op">-</span>lambd <span class="op">/</span> <span class="dv">2</span>:
                phi_new[j] <span class="op">=</span> (discri <span class="op">+</span> lambd <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> (n <span class="op">-</span> (j <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> <span class="dv">1</span>)
            <span class="cf">elif</span> discri <span class="op">&gt;</span> lambd <span class="op">/</span> <span class="dv">2</span>:
                phi_new[j] <span class="op">=</span> (discri <span class="op">-</span> lambd <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> (n <span class="op">-</span> (j <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> <span class="dv">1</span>)
        phi_new <span class="op">=</span> phi_new[<span class="dv">1</span>:]
        phisums_new <span class="op">=</span> phisums_new[<span class="dv">1</span>:]
        theta <span class="op">=</span> np.append(theta_1_new, theta_1_new <span class="op">+</span> phisums_new)
        cost <span class="op">=</span> <span class="bu">sum</span>((y <span class="op">-</span> theta) <span class="op">**</span> <span class="dv">2</span>) <span class="op">+</span> lambd <span class="op">*</span> <span class="bu">sum</span>(<span class="bu">abs</span>(phi_new))
        theta_1_new <span class="op">=</span> (<span class="bu">sum</span>(y) <span class="op">-</span> <span class="bu">sum</span>(phisums_new)) <span class="op">/</span> n
        phisums_old <span class="op">=</span> phisums_new
        iteration <span class="op">+=</span> <span class="dv">1</span>
        costs.append(cost)
        there_is_a_progress <span class="op">=</span> <span class="kw">not</span> (<span class="bu">abs</span>(costs[iteration <span class="op">-</span> <span class="dv">1</span>] <span class="op">-</span> cost) <span class="op">&lt;=</span> eps)
        
    result <span class="op">=</span> {
        <span class="st">&#39;theta&#39;</span>: theta,
        <span class="st">&#39;phi&#39;</span>: phi_new,
        <span class="st">&#39;lambd&#39;</span>: lambd,
        <span class="st">&#39;iteration&#39;</span>: iteration,
        <span class="st">&#39;costs&#39;</span>: np.array(costs)
    }
    
    <span class="cf">return</span> result</code></pre></div>
<p>Let’s see if it works:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Loading data from R</span>
y <span class="op">=</span> np.array(r.y) <span class="co"># the same y as in R</span>
t <span class="op">=</span> np.array(r.t)
start <span class="op">=</span> np.array(r.Start)

t_0 <span class="op">=</span> np.append(<span class="dv">0</span>, t)
start_py <span class="op">=</span> dt.now()
example1 <span class="op">=</span> fusion_estimates(y <span class="op">=</span> y, lambd <span class="op">=</span> <span class="dv">1</span>, theta <span class="op">=</span> start)
end_py <span class="op">=</span> dt.now()
plt.plot(t_0, example1[<span class="st">&#39;costs&#39;</span>])
plt.xlabel(<span class="st">&#39;Iteration&#39;</span>)
plt.ylabel(<span class="st">&#39;Cost&#39;</span>)
plt.show()</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/does_work1-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">plt.clf()
plt.scatter(t, y, facecolors <span class="op">=</span> <span class="st">&#39;none&#39;</span>, edgecolors <span class="op">=</span> <span class="st">&#39;#1f77b4&#39;</span>, alpha <span class="op">=</span> .<span class="dv">5</span>)
plt.plot(t, start, c <span class="op">=</span> <span class="st">&#39;black&#39;</span>, label <span class="op">=</span> <span class="st">&#39;Start&#39;</span>)
plt.plot(t, example1[<span class="st">&#39;theta&#39;</span>], c <span class="op">=</span> <span class="st">&#39;orange&#39;</span>, label <span class="op">=</span> <span class="st">&#39;Estimated theta&#39;</span>)
plt.legend(loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>)
plt.xlabel(<span class="st">&#39;t&#39;</span>)
plt.ylabel(<span class="st">&#39;y&#39;</span>)
plt.show()</code></pre></div>
<p><img src="non_separable_penalty_files/figure-html/does_work2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Yes it does. In Python, it takes:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">str</span>(end_py <span class="op">-</span> start_py)</code></pre></div>
<pre><code>## &#39;0:01:52.618012&#39;</code></pre>
<p>minutes (!). In R, it takes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">end_r <span class="op">-</span><span class="st"> </span>start_r</code></pre></div>
<pre><code>## Time difference of 13.06109 secs</code></pre>
</div>
</div>
<div id="session-info" class="section level1">
<h1>Session Info</h1>
<p>R session info:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows &gt;= 8 x64 (build 9200)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
## [5] LC_TIME=English_Canada.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] ggplot2_3.1.1   dplyr_0.8.1     reticulate_1.12 rmarkdown_1.12 
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.1       pillar_1.4.0     compiler_3.6.0   plyr_1.8.4      
##  [5] prettydoc_0.2.1  tools_3.6.0      zeallot_0.1.0    digest_0.6.18   
##  [9] jsonlite_1.6     evaluate_0.13    tibble_2.1.1     gtable_0.3.0    
## [13] lattice_0.20-38  png_0.1-7        pkgconfig_2.0.2  rlang_0.3.4     
## [17] Matrix_1.2-17    cli_1.1.0        rstudioapi_0.10  yaml_2.2.0      
## [21] xfun_0.7         ezknitr_0.6      withr_2.1.2      stringr_1.4.0   
## [25] knitr_1.23       hms_0.4.2        vctrs_0.1.0      grid_3.6.0      
## [29] tidyselect_0.2.5 glue_1.3.1       R6_2.4.0         fansi_0.4.0     
## [33] readr_1.3.1      purrr_0.3.2      tidyr_0.8.3      magrittr_1.5    
## [37] backports_1.1.4  scales_1.0.0     htmltools_0.3.6  assertthat_0.2.1
## [41] colorspace_1.4-1 labeling_0.3     utf8_1.1.4       stringi_1.4.3   
## [45] lazyeval_0.2.2   munsell_0.5.0    crayon_1.3.4</code></pre>
<p>Python session info:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> sinfo
sinfo.sinfo()</code></pre></div>
<pre><code>## -----
## matplotlib   3.0.2
## numpy        1.15.0
## scipy        1.1.0
## -----
## Python 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 23:09:28) [MSC v.1916 64 bit (AMD64)]
## Windows-10-10.0.17763
## 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel
## -----
## Session information updated at 2019-05-29 18:10</code></pre>
</div>
</section>

<!-- Footer -->
<!-- Reference: https://holtzy.github.io/Pimp-my-rmd/ -->
&nbsp; <!-- whitespace -->
<hr /> <!-- line -->
<p style="text-align: center;">
    © 2019 Junkyu Park
    <br>
    Powered by the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> from the <a href="https://github.com/yixuan/prettydoc">prettydoc::html_pretty</a> engine
</p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <span style="color: #555555;"><em>joon3216@gmail.com</em></span>
    <br>
    <a href="https://www.facebook.com/asdfzxcvjkl1" class="fa fa-facebook"></a>
    <a href="https://github.com/joon3216" class="fa fa-github"></a>
    <a href="https://linkedin.com/in/asdfzxcvjkl1/" class="fa fa-linkedin"></a>
    <a href="https://twitter.com/joon3216" class="fa fa-twitter"></a>
</p>
&nbsp; <!-- whitespace -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
