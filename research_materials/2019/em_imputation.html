<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Junkyu Park" />


<title>EM imputation</title>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139050237-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-139050237-1');
</script>
<!-- A new navigation bar style settings -->
<style type="text/css">
body
{
    margin: 0;
    padding: 0;
    font-family: sans-serif;
}
/* at the top */
#navbar
{
    position: sticky;
    z-index: 1000; /* new; why: make navbar closest to the observer */
    top: 0;
    left: 0;
    padding: 0; /* old: 10px 25px */
    background: rgba(28, 44, 56, 0.99);
    width: 100%;
    height: 50px;
    box-sizing: border-box;
    border-bottom: 1px solid #EAEAEB;
    transition: .5s;
}
#navbar .logo
{
    float: left;
}
#navbar .logo img
{
    height: 30px;
    /* new: margin; why: so that in header, padding can be 0 */
    /* note: header nav ul li a has margin 20px on left and right, 
    so here I let the right margin of img to be 5px so that it matches
    with the left margin 25px */
    margin: 10px 5px 10px 25px; 
}
#navbar nav
{
    float: left;
}
#navbar nav ul
{
    margin: 0;
    padding: 0;
    display: flex;

}
#navbar nav ul li
{
    padding: 0;
    list-style: none;
    position: relative;
    /* new: margin and padding; why: header padding is now 0 */
    margin: 0;
    padding: 8.5px 0 8.5px 0;
}
/* new; why: texts with arrow on the right gets more space  */
#navbar nav ul li.sub-menu
{
    /* why 8.5px: that's the value in header nav ul li padding */
    padding: 8.5px 27.5px 8.5px 0;
    padding-bottom: 12px;
    /* new; why: to make dropdown menu available once the mouse is on the menu item that it belongs, and to not affect other menu items that is not of class sub-menu */
}

#navbar nav ul li.sub-menu:before
{
    content: '\f0d7'; /* &#9660 ▼ nabla */
    font-family: fontAwesome; /* old: sans-serif */
    font-size: 16pt;
    position: absolute;
    /*line-height: 30px;*/
    color: #ffffff;
    top: 7pt;
    right: 22.5px;
    cursor: pointer;
}
#navbar nav ul li.active.sub-menu:before
{
    content: '\f0d8';  /* &#9650 ▲ Delta */
    font-family: fontAwesome; /* new */
    font-size: 16pt;
    position: absolute;
    color: #ffffff;
    top: 7pt;
    right: 22.5px;
    cursor: pointer;
}
#navbar nav ul li ul
{
    position: absolute;
    left: 0;
    top: 50px; /* controls the box position of dropdown menus */
    background: rgba(57, 143, 209, 0.99);
    display: none;
}
#navbar nav ul li.active ul
{
    display: block;
}

/* new; why: make dropdown menu box fit to the menu above */
/* padding: 0; is for slimmer individual dropdown menu items */
/* old */
#navbar nav ul li.sub-menu ul li
{
    display: block;
    width: 200px;
    padding: 5px 0;
}

/* new: header nav ul li ul li a */
/* why: giving an indentation */
#navbar nav ul li ul li a
{
    margin: 0 40px;
}

/* header nav ul li#projects.sub-menu ul li
{
    display: block;
    width: 115px;
    padding: 0;
}
header nav ul li#rm.sub-menu ul li
{
    display: block;
    width: 197px;
    padding: 0;
} */

#navbar nav ul li a
{
    height: 30px;
    line-height: 30px;
    padding: 0; /* old: 0 20px, and margin didn't exist; why change: to make text the only clickable object */
    margin: 0 20px;
    color: #ffffff;
    text-decoration: none;
    text-shadow: none; /* new; why: to be compatible with the Tactile theme */
    /*display: block;*/
}

/* new: news; why add: to make News go to the right */
/* commented out because the same effect is achieved by having 
header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
/* header nav ul li.news
{
    margin: 0 0 0 20px;
} */

/* new: rm; why: to make r_m go to the right */
/* commented out because the same effect is achieved by having 
header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
/* header nav ul li#rm
{
    margin: 0 0 0 20px;
} */

#navbar nav ul li a:hover
{
    color: #ffffff;
}

/* new: header nav ul li:hover ul, why: to make dropdown menu appear whenever mouse is above */
#navbar nav ul li:hover ul
{
    display: block;
}

.menu-toggle
{
    color: #ffffff;
    float: right;
    line-height: 30px;
    font-size: 24px;
    cursor: pointer;
    display: none;
}
@media (max-width: 800px) /* old1: 991px; old2: 721px */
{
    /* at the top */
    #navbar
    {
        padding: 0; /* old: 10px 25px */
    }
    .menu-toggle
    {
        display: block;
        margin: 10px 25px /* new; why: header padding is now 0 */
    }
    #navbar nav
    {
        /*display: none;*/
        position: absolute;
        width: 100%;
        height: calc(100vh - 50px);
        background: rgba(28, 44, 56, 0.99);
        top: 50px;
        left: -100%;
        transition: .5s;
    }
    #navbar nav.active
    {
        left: 0;
    }
    #navbar nav ul
    {
        display: block;
        /*text-align: center;*/
    }
    #navbar nav ul li a
    {
        border-bottom: 1px solid rgba(255, 255, 255, .5);
        height: 50px;
        line-height: 50px;
        padding: 0 20px;
    }
    #navbar nav ul li.active ul
    {
        position: relative;
    }
    #navbar nav ul li ul li
    {
        width: 100%;
    }

    /* new: header nav ul li.sub-menu */
    /* why: so that dropdown menus fill the entire row in mobile */
    #navbar nav ul li.sub-menu
    {
        padding: 8.5px 0;
    }

    #navbar nav ul li.sub-menu:before
    {
        content: '+'; /* old: &#9660 nabla */
        font-size: 20pt;
        font-family: sans-serif;
        position: absolute;
        line-height: 30px;
        color: #ffffff;
        top: 5pt;
        right: 25px;
        cursor: pointer;
    }
    #navbar nav ul li.active.sub-menu:before
    {
        content: '-';  /* new: &#9650 Delta */
        font-size: 30pt;
        top: 5pt;
        right: 25px;
        line-height: 30px;
        cursor: pointer;
    }
    #navbar nav ul li ul
    {
        position: absolute;
        left: 0;
        top: 0px; /* controls the box position of 2018 and 2019 under Research materials */
        background: rgba(57, 143, 209, 0.99);
        display: none;
    }

    /* new: hover and active
    why: do not display drop down menus when mouse is over it
    and looking in mobile, but display them when plus signs are clicked */
    #navbar nav ul li:hover ul
    {
        display: none;
    }
    #navbar nav ul li.active ul
    {
        display: block;
    }

    /* new: News; why: to make News align with the others in mobile */
    /* commented out since Research Materials uses different method
    to get more space on its right (header nav ul li.sub-menu padding) */

    /* header nav ul li.news
    {
        margin: 0;
    } */
    /* new: rm; why: to make rm align with the others in mobile */
    /* commented out for the same reason */
    /* header nav ul li#rm
    {
        margin: 0;
    } */

    /* while scrolling */

}

/* while scrolling */
#navbar.black
{
    background: rgba(21, 92, 148, .7);
}
</style>

<!-- 1. Navigation bar color change as one scrolls -->
<!-- by adding a new class="black" while scrolling -->
<script src="https://code.jquery.com/jquery-3.3.1.js"></script>
<script type="text/javascript">
    $(window).on('scroll', function(){
        if ($(window).scrollTop()){
           navbar.classList.add('black');
           /* old: $('header').addClass('black'); */
        }
        else
        {
            navbar.classList.remove('black');
            /* old: $('header').removeClass('black'); */
        }
    })
</script>

<!-- 2. Navigation bar slides from the left in mobile -->
<!-- 3. Only one dropdown menu at a time will appear -->
<script type="text/javascript">
    $(document).ready(function(){
        $('.menu-toggle').click(function(){
            $('nav').toggleClass('active')
        })
        $('ul li').click(function(){
            $(this).siblings().removeClass('active');
            $(this).toggleClass('active');
        })
    })
</script>

<!-- Using caret down and up symbols -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
<link rel="icon" href="../../style/all_orange_jp.png">


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link rel="stylesheet" href="em_imputation_files/style.css" type="text/css" />

</head>

<body>


<!-- A new navigation bar -->
<div id="navbar">
    <div class="logo">
        <a href="../../index.html"><img src="../../style/all_orange_jp.png"></a>
    </div>
    <nav>
        <ul>
            <li>
                <a href="../../cv.html">About</a>
            </li>
            <li class="sub-menu" id="projects">
                <a href="../../projects.html">Projects</a>
                <ul>
                    <li>
                        <a href="../../projects/2019.html">2019</a>
                    </li>
                </ul>
            </li>
            <li class="sub-menu" id="rm">
                <a href="../../research_materials.html">Research materials</a>
                <ul>
                    <li>
                        <a href="../../research_materials/2018.html">2018</a>
                    </li>
                    <li>
                        <a href="../../research_materials/2019.html">2019</a>
                    </li>
                </ul>
            </li>
            <li id="news">
                <a href="../../news.html">News</a>
            </li>
        </ul>
    </nav>
    <div class="menu-toggle">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
</div>


<section class="page-header">
<h1 class="title toc-ignore project-name">EM imputation</h1>
<h4 class="author project-author">Junkyu Park</h4>
</section>



<section class="main-content">
<p>The following external R packages/functions are used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
gather &lt;-<span class="st"> </span>tidyr<span class="op">::</span>gather
grid.arrange &lt;-<span class="st"> </span>gridExtra<span class="op">::</span>grid.arrange
mvrnorm &lt;-<span class="st"> </span>MASS<span class="op">::</span>mvrnorm
separate &lt;-<span class="st"> </span>tidyr<span class="op">::</span>separate
unite &lt;-<span class="st"> </span>tidyr<span class="op">::</span>unite</code></pre></div>

<div id="TOC" class="toc" style="padding:2rem 2rem 0 0;">
<ul style="list-style:none;">
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#imputation">2. Imputation</a><ul>
<li><a href="#terminology">Terminology</a></li>
<li><a href="#the-algorithm">The algorithm</a><ul>
<li><a href="#how-it-works">How it works</a></li>
<li><a href="#e-step">E-step</a></li>
<li><a href="#m-step">M-step</a></li>
</ul></li>
<li><a href="#simulating-nas">Simulating <code>NA</code>s</a></li>
<li><a href="#imputing-nas">Imputing <code>NA</code>s</a></li>
</ul></li>
<li><a href="#performance">3. Performance</a></li>
<li><a href="#session-info">Session Info</a></li>
<li><a href="#related-pages">Related pages</a></li>
</ul>
</div>
&nbsp;

<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<p>Assuming normality of the data, this note demonstrates the procedure to impute missing components in each data point using the EM algorithm. We will first simulate iid multivariate normal samples, randomly replace some of the components in the data with <code>NA</code>’s, and apply EM algorithm to impute those components. We will compare values of the original parameter, the estimate computed by imputed data, and the estimate computed using only the observed data to measure a performance of imputation.</p>
</div>
<div id="imputation" class="section level1">
<h1>2. Imputation</h1>
<div id="terminology" class="section level2">
<h2>Terminology</h2>
<p>In this note, the following terms will be used in a following context:</p>
<p><img src="em_imputation_terms.png" width="100%" style="display: block; margin: auto;" /></p>
<ul>
<li>data point: an entire row in a table (a green box)</li>
<li>data or dataset: the table itself (a big black box)</li>
<li>component: a subset of data point (e.g. a lightblue grey box)</li>
</ul>
</div>
<div id="the-algorithm" class="section level2">
<h2>The algorithm</h2>
<p>Before generating the data to fiddle with, I will first describe how this algorithm works.</p>
<p>Assuming <span class="math inline">\(X_i = (X_{i1}, \dots, X_{ij}, \dots, X_{ip}) \stackrel{iid}{\sim} N_p(\mu, \Sigma)\)</span>, let’s define: <span class="math display">\[C_{ij} := \begin{cases} 1 &amp; X_{ij} \text{ is observed} \\ 0 &amp; X_{ij} \text{ is missing} \end{cases}\]</span></p>
<p>and <span class="math inline">\(O_i\)</span> and <span class="math inline">\(M_i\)</span> as:</p>
<span class="math display">\[\begin{align*}
O_i &amp;:= \{j \text{ | } C_{ij} = 1 \} \\
M_i &amp;:= \{j \text{ | } C_{ij} = 0 \}
\end{align*}\]</span>
<p>i.e. <span class="math inline">\(O_i\)</span> and <span class="math inline">\(M_i\)</span> are sets of <span class="math inline">\(j\)</span> values in <span class="math inline">\(X_i\)</span> that are observed and missing respectively. Since every component in <span class="math inline">\(X_i\)</span> is either observed or missing, we see that: <span class="math display">\[O_i \cup M_i = \{1, 2, \dots, n \}\]</span> and also: <span class="math display">\[O_i \cap M_i = \varnothing\]</span> Assume <span class="math inline">\(|M_i| &lt; n\)</span> for all <span class="math inline">\(i\)</span> (where <span class="math inline">\(|M_i|\)</span> denotes the cardinality of <span class="math inline">\(M_i\)</span>), i.e. no data points have all the components missing, i.e. every data point has at least one component that is observed. For example, if <span class="math inline">\(n = 5\)</span>, <span class="math inline">\(p = 4\)</span>, <span class="math inline">\(X_i \stackrel{iid}{\sim} N_4 (\mu, \Sigma)\)</span> for some <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, and: <span class="math display">\[\mathbf{X} := \begin{bmatrix} X_1^T \\ X_2^T \\ X_3^T \\ X_4^T \\ X_5^T \end{bmatrix}_{5 \times 4} = \begin{bmatrix} \text{NA} &amp; \text{NA} &amp; 0.7213 &amp; \text{NA} \\ 1.2607 &amp; \text{NA} &amp; -2.0860 &amp; \text{NA} \\ \text{NA} &amp; 0.2322 &amp;  \text{NA} &amp;  2.1117 \\ -1.3510 &amp; -1.4308 &amp; -0.1900 &amp; 0.9055 \\ -0.4004 &amp; \text{NA} &amp; 0.1413 &amp; 0.0657 \end{bmatrix}_{5 \times 4}\]</span> then: <span class="math display">\[C = \begin{bmatrix} 0 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 1 \end{bmatrix} \implies \begin{cases} O_1 = \{3 \}, &amp; M_1 = \{1, 2, 4 \} \\ O_2 = \{1, 3 \}, &amp; M_2 = \{2, 4 \} \\ O_3 = \{2, 4 \}, &amp; M_3 = \{1, 3 \} \\ O_4 = \{1, 2, 3, 4 \}, &amp; M_4 = \{ \} \\ O_5 = \{1, 3, 4 \}, &amp; M_5 = \{ 2 \} \end{cases}\]</span></p>
<p>That is, the assumption prevents us to consider data points that look like <span class="math inline">\(\text{(NA, NA, NA, NA)}\)</span> in <span class="math inline">\(\mathbf{X}\)</span>. Notice that in the example above, no <span class="math inline">\(M_i\)</span> is equal to <span class="math inline">\(\{1, 2, 3, 4 \}\)</span>.</p>
<p>Let’s also suppose that we somehow have <span class="math inline">\(\theta^{(0)} = (\mu^{(0)}, \Sigma^{(0)})\)</span>, the initial estimate for parameters. We may get this by computing estimates using the observed components only. Details for the initial estimate will be discussed in a moment.</p>
<div id="how-it-works" class="section level3">
<h3>How it works</h3>
<p>“E” stands for the expectation, and “M” stands for the maximization. The EM algorithm is an optimization algorithm that maximizes the “expected complete data log likelihood” by some iterative means under the (conditional) distribution of unobserved components. In other words, the expectation step (or E-step) at iteration <span class="math inline">\(t\)</span> computes:</p>
<span class="math display">\[\begin{align*}
Q(\theta \text{ | } \theta^{(t)}) &amp;:= E_{\theta^{(t)}} \big[ \log L(\theta ; \mathbf{Y}_{O}, \mathbf{Y}_{M} ) \text{ | } \mathbf{Y}_{O} = \mathbf{y}_O \big] \\
&amp;= \sum_{i = 1}^{n} E_{\theta^{(t)}} \big[ \log L(\theta ; Y_{iO_i}, Y_{iM_i} ) \text{ | } Y_{i O_i} = y_{i O_i} \big]
\end{align*}\]</span>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{Y} = (\mathbf{Y}_O, \mathbf{Y}_M)\)</span>: a complete data, or a collection of all <span class="math inline">\(n\)</span> data points</li>
<li><span class="math inline">\(\mathbf{Y}_O\)</span>: a collection of all observed components</li>
<li><span class="math inline">\(\mathbf{Y}_M\)</span>: a collection of all missing (or unobserved) components</li>
<li><span class="math inline">\(Y_i = (Y_{i O_i}, Y_{i M_i})\)</span>: a complete <span class="math inline">\(i\)</span><sup>th</sup> data point</li>
<li><span class="math inline">\(Y_{i O_i}\)</span>: an observed component of the <span class="math inline">\(i\)</span><sup>th</sup> data point</li>
<li><span class="math inline">\(Y_{i M_i}\)</span>: a missing component of the <span class="math inline">\(i\)</span><sup>th</sup> data point</li>
</ul>
<p><span class="math inline">\(E_{\theta^{(t)}}(\cdot \text{ | } Y_O = y_O)\)</span> means an expectation under <span class="math inline">\(Y_{M} \text{ | } (Y_O = y_O, \theta^{(t)})\)</span>. And due to the iid assumption of data points, we have <span class="math inline">\(\log f(\mathbf{Y}) = \sum_{i = 1}^{n} \log f(Y_i)\)</span>.</p>
<p>The maximization step (or M-step) at iteration <span class="math inline">\(t\)</span> finds: <span class="math display">\[\theta^{(t + 1)} := \underset{\theta}{\text{argmax}} \{ Q(\theta \text{ | } \theta^{(t)}) \}\]</span> These two steps are repeated until the parameter estimate converges.</p>
</div>
<div id="e-step" class="section level3">
<h3>E-step</h3>
<p>Say we’re at iteration <span class="math inline">\(t\)</span> with <span class="math inline">\(\theta^{(t)} = (\mu^{(t)}, \Sigma^{(t)})\)</span>. For each <span class="math inline">\(X_i \sim N_p (\mu, \Sigma)\)</span>, let <span class="math inline">\(Q_i(\theta \text{ | } \theta^{(t)})\)</span> be the expected log likelihood. This is equal to:</p>
<span class="math display">\[\begin{align*}
&amp;E_{\theta^{(t)}} \big[ -\frac{1}{2} \log |2 \pi \Sigma | - \frac{1}{2} (X_i - \mu)^T \Sigma^{-1} (X_i - \mu)  \text{ | } X_{i O_i} = x_{i O_i} \big] \\
=&amp; -\frac{1}{2} \log | 2 \pi \Sigma | - \frac{1}{2} E_{\theta^{(t)}} \big[ (X_i - \mu)^T \Sigma^{-1} (X_i - \mu)  \text{ | } X_{i O_i} = x_{i O_i} \big] \\
=&amp; -\frac{1}{2} \log | 2 \pi \Sigma | - \frac{1}{2} E_{\theta^{(t)}} \big[ (J_{\sigma_i} X_i - J_{\sigma_i} \mu)^T J_{\sigma_i} \Sigma^{-1} J_{\sigma_i}^T (J_{\sigma_i} X_i - J_{\sigma_i} \mu)  \text{ | } X_{i O_i} = x_{i O_i} \big]
\end{align*}\]</span>
<p>where <span class="math inline">\(J_{\sigma_i}\)</span> is a <span class="math inline">\(p \times p\)</span> permutation matrix for <span class="math inline">\(X_i\)</span> so that <span class="math inline">\(J_{\sigma_i} X_i = (X_{i M_i}, X_{i O_i})\)</span>. For example: if <span class="math inline">\(X_i = (\text{NA}, 2, 3, \text{NA})\)</span>, then we may let: <span class="math display">\[J_{\sigma_i} = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \end{bmatrix}\]</span> so that: <span class="math display">\[J_{\sigma_i} X_i = \begin{bmatrix} \text{NA} \\ \text{NA} \\ 2 \\ 3 \end{bmatrix}\]</span></p>
<p>Also, for any <span class="math inline">\(\sigma_i\)</span> (permutation), we get <span class="math inline">\(J_{\sigma_i}^T J_{\sigma_i} = I_p\)</span> (i.e. <span class="math inline">\(J_{\sigma_i}^{-1} = J_{\sigma_i}^T\)</span>). Now:</p>
<span class="math display">\[\begin{align*}
&amp;E_{\theta^{(t)}} \big[ (J_{\sigma_i} X_i - J_{\sigma_i} \mu)^T J_{\sigma_i} \Sigma^{-1} J_{\sigma_i}^T (J_{\sigma_i} X_i - J_{\sigma_i} \mu)  \text{ | } X_{i O_i} = x_{i O_i} \big] \\
=&amp; E_{\theta^{(t)}} \Big[ \begin{bmatrix} X_{i M_i} - \mu_{M_i} \\  X_{i O_i} - \mu_{O_i} \end{bmatrix}^T \begin{bmatrix} (\Sigma^{-1})_{M_i M_i} &amp; (\Sigma^{-1})_{M_i O_i} \\ (\Sigma^{-1})_{O_i M_i} &amp; (\Sigma^{-1})_{O_i O_i} \end{bmatrix} \begin{bmatrix} X_{i M_i} - \mu_{M_i} \\  X_{i O_i} - \mu_{O_i} \end{bmatrix}  \text{ | } X_{i O_i} = x_{i O_i} \Big] \\
=&amp;\hspace{16pt} E_{\theta^{(t)}} \Big[ ( X_{i M_i} - \mu_{M_i})^T (\Sigma^{-1})_{M_i M_i} ( X_{i M_i} - \mu_{M_i}) \text{ | } X_{i O_i} = x_{i O_i} \Big] \\ 
&amp;+ 2 E_{\theta^{(t)}} \Big[ ( X_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i M_i} ( X_{i M_i} - \mu_{M_i}) \text{ | } X_{i O_i} = x_{i O_i} \Big] \\ 
&amp;+ \hspace{5pt} E_{\theta^{(t)}} \Big[ ( X_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i O_i} (  X_{i O_i} - \mu_{O_i}) \text{ | } X_{i O_i} = x_{i O_i} \Big] \\
=&amp;\hspace{16pt} E_{\theta^{(t)}} \Big[ ( X_{i M_i} - \mu_{M_i})^T (\Sigma^{-1})_{M_i M_i} ( X_{i M_i} - \mu_{M_i}) \text{ | } X_{i O_i} = x_{i O_i} \Big] \\ 
&amp;+ 2 ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i M_i} E_{\theta^{(t)}} \Big[  X_{i M_i} - \mu_{M_i} \text{ | } X_{i O_i} = x_{i O_i} \Big] \\ 
&amp;+ \hspace{5pt} ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i O_i} (  x_{i O_i} - \mu_{O_i})
\end{align*}\]</span>
<p>Given <span class="math inline">\(\theta^{(t)} = (\mu^{(t)}, \Sigma^{(t)})\)</span> at iteration <span class="math inline">\(t\)</span>, we have that for all <span class="math inline">\(i\)</span>’s with <span class="math inline">\(|M_i| \neq 0\)</span>: <span class="math display">\[X_{iM_i} \text{ | } \big( X_{i O_i} = x_{i O_i}, \theta^{(t)} \big) \sim N_{|M_i|} \big(\mu_{M_i}^{(t)} + \Sigma_{M_i O_i}^{(t)} (\Sigma_{O_i O_i}^{(t)})^{-1} (x_{i O_i} - \mu_{O_i}^{(t)}), \Sigma_{M_i M_i \cdot O_i}^{(t)} \big)\]</span> where <span class="math inline">\(\Sigma_{M_i M_i \cdot O_i}^{(t)} := \Sigma_{M_i M_i}^{(t)} - \Sigma_{M_i O_i}^{(t)} (\Sigma_{O_i O_i}^{(t)})^{-1} \Sigma_{O_i M_i}^{(t)}\)</span>. Define: <span class="math display">\[\widetilde{\mu}_{i M_i}^{(t)} := \mu_{M_i}^{(t)} + \Sigma_{M_i O_i}^{(t)} (\Sigma_{O_i O_i}^{(t)})^{-1} (x_{i O_i} - \mu_{O_i}^{(t)})\]</span> so that we can write: <span class="math display">\[X_{iM_i} \text{ | } \big( X_{i O_i} = x_{i O_i}, \theta^{(t)} \big) \sim N_{|M_i|} \big(\widetilde{\mu}_{i M_i}^{(t)}, \Sigma_{M_i M_i \cdot O_i}^{(t)} \big)\]</span> That is: <span class="math display">\[X_{iM_i} - \mu_{M_i} \text{ | } \big( X_{i O_i} = x_{i O_i}, \theta^{(t)} \big) \sim N_{|M_i|} \big(\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}, \Sigma_{M_i M_i \cdot O_i}^{(t)} \big)\]</span> Furthermore, we obtain the distribution of: <span class="math display">\[[(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(X_{iM_i} - \mu_{M_i}) \text{ | } \big( X_{i O_i} = x_{i O_i}, \theta^{(t)} \big)\]</span> which is: <span class="math display">\[N_{|M_i|} \Big( [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}), \text{ }[(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}} \Sigma_{M_i M_i \cdot O_i}^{(t)} [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}} \Big)\]</span> since <span class="math inline">\([(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}\)</span> is symmetric.</p>
<p>Using the fact that <span class="math inline">\(E(WW^T) = Var(W) + E(W)E(W)^T\)</span>, we get:</p>
<span class="math display">\[\begin{align*}
&amp;E_{\theta^{(t)}} \Big[ ( X_{i M_i} - \mu_{M_i})^T (\Sigma^{-1})_{M_i M_i} ( X_{i M_i} - \mu_{M_i}) \text{ | } X_{i O_i} = x_{i O_i} \Big] \\
=&amp; E_{X_{i O_i} = x_{i O_i}, \theta^{(t)}} \Big[ \big[[(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(X_{iM_i} - \mu_{M_i}) \big]^T \big[[(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(X_{iM_i} - \mu_{M_i}) \big] \Big] \\
=&amp; E_{X_{i O_i} = x_{i O_i}, \theta^{(t)}} \Big[ W_i^T W_i \Big] \\
=&amp; \text{tr} \Big( E_{X_{i O_i} = x_{i O_i}, \theta^{(t)}} \big[ W_i W_i^T \big] \Big) \\
=&amp;\hspace{11pt} \text{tr} \Big( [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}} \Sigma_{M_i M_i \cdot O_i}^{(t)} [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}} \Big) \\
&amp;+ \text{tr} \Big( \big[ [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \big] \big[ [(\Sigma^{-1})_{M_i M_i}]^{\frac{1}{2}}(\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \big]^T \Big) \\
=&amp;\hspace{11pt} \text{tr} \Big( [(\Sigma^{-1})_{M_i M_i}] \Sigma_{M_i M_i \cdot O_i}^{(t)} \Big) \\
&amp;+ (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i})^T [(\Sigma^{-1})_{M_i M_i}] (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i})
\end{align*}\]</span>
<p>and hence:</p>
<span class="math display">\[\begin{align*}
&amp;E_{\theta^{(t)}} \big[ (J_{\sigma_i} X_i - J_{\sigma_i} \mu)^T J_{\sigma_i} \Sigma^{-1} J_{\sigma_i}^T (J_{\sigma_i} X_i - J_{\sigma_i} \mu)  \text{ | } X_{i O_i} = x_{i O_i} \big] \\
=&amp; \text{tr} \Big( [(\Sigma^{-1})_{M_i M_i}] \Sigma_{M_i M_i \cdot O_i}^{(t)} \Big) + (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i})^T [(\Sigma^{-1})_{M_i M_i}] (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \\
&amp;+ 2 ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i M_i} (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \\ 
&amp;+ \hspace{5pt} ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i O_i} (  x_{i O_i} - \mu_{O_i})
\end{align*}\]</span>
<p>Therefore:</p>
<span class="math display">\[\begin{align*}
Q_i(\theta \text{ | } \theta^{(t)}) = &amp;-\frac{1}{2} \log |2 \pi \Sigma| - \frac{1}{2} \Big[ \text{tr} \big( [(\Sigma^{-1})_{M_i M_i}] \Sigma_{M_i M_i \cdot O_i}^{(t)} \big) \\
&amp;\hspace{15pt} + (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i})^T (\Sigma^{-1})_{M_i M_i} (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \\
&amp;\hspace{15pt} + 2 ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i M_i} (\widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}) \\ 
&amp;\hspace{15pt} + \hspace{5pt} ( x_{i O_i} - \mu_{O_i})^T (\Sigma^{-1})_{O_i O_i} (  x_{i O_i} - \mu_{O_i}) \Big] \\
= &amp;-\frac{1}{2} \log |2 \pi \Sigma| - \frac{1}{2} \Big[ \text{tr} \big( [(\Sigma^{-1})_{M_i M_i}] \Sigma_{M_i M_i \cdot O_i}^{(t)} \big) \\
&amp;\hspace{10pt} + \begin{bmatrix} \widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i} \\ x_{i O_i} - \mu_{O_i} \end{bmatrix}^T \begin{bmatrix} (\Sigma^{-1})_{M_i M_i} &amp; (\Sigma^{-1})_{M_i O_i} \\ (\Sigma^{-1})_{O_i M_i} &amp; (\Sigma^{-1})_{O_i O_i} \end{bmatrix} \begin{bmatrix} \widetilde{\mu}_{i M_i}^{(t)} - \mu_{M_i}\\ x_{i O_i} - \mu_{O_i} \end{bmatrix} \Big] \\
= &amp;-\frac{1}{2} \log |2 \pi \Sigma| - \frac{1}{2} \Big[ \text{tr} \big( [(\Sigma^{-1})_{M_i M_i}] \Sigma_{M_i M_i \cdot O_i}^{(t)} \big) \\
&amp;\hspace{10pt} + (\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \Big]
\end{align*}\]</span>
<p>where <span class="math inline">\(\widetilde{x}_i^{(t)} = (x_{i1}^{(t)}, \dots, x_{ip}^{(t)})\)</span> is the data point such that <span class="math inline">\(x_{i M_i}^{(t)} = (x_{ij}^{(t)})_{j \in M_i}\)</span> is replaced with <span class="math inline">\(\widetilde{\mu}_{i M_i}^{(t)}\)</span> (and that <span class="math inline">\(x_{i O_i}^{(t)} = x_{i O_i}\)</span> always stays the same since it is observed and not subject to imputation). Note that at <span class="math inline">\(t = 0\)</span>, <span class="math inline">\(x_{i M_i}^{(0)}\)</span> is just a vector of missing values. And finally: <span class="math display">\[Q(\theta \text{ | } \theta^{(t)}) = \sum_{i = 1}^{n} Q_i(\theta \text{ | } \theta^{(t)})\]</span></p>
</div>
<div id="m-step" class="section level3">
<h3>M-step</h3>
<p>Differentiating <span class="math inline">\(Q(\theta \text{ | } \theta^{(t)})\)</span> with respect to <span class="math inline">\(\mu\)</span> yields:</p>
<span class="math display">\[\begin{align*}
\nabla_{\mu} Q(\theta \text{ | } \theta^{(t)}) &amp;= \sum_{i = 1}^{n} \nabla_{\mu} Q_i (\theta \text{ | } \theta^{(t)}) \\
&amp;= \sum_{i = 1}^{n} \nabla_{\mu} \Big( -\frac{1}{2} (\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \Big) \\
&amp;= -\frac{1}{2} \sum_{i = 1}^{n} \nabla_{\mu} (\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \\
&amp;= -\frac{1}{2} \sum_{i = 1}^{n} 2 \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \nabla_{\mu} (\widetilde{x}_i^{(t)} - \mu) \\
&amp;= -\frac{1}{2} \sum_{i = 1}^{n} 2 \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) (O - I_p) \\
&amp;= \Sigma^{-1} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu)
\end{align*}\]</span>
<p>The maximizer <span class="math inline">\(\mu^{(t + 1)}\)</span> must satisfy <span class="math inline">\(\Sigma^{-1} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)}) = \mathbf{0}\)</span> since <span class="math inline">\(Q(\theta \text{ | } \theta^{(t)})\)</span> is a concave function with respect to <span class="math inline">\(\mu\)</span>. Given that <span class="math inline">\(\Sigma^{-1}\)</span> is postivie-definite:</p>
<span class="math display">\[\begin{align*}
&amp;\Sigma^{-1} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)}) = \mathbf{0} \\
\iff&amp; \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)}) = \mathbf{0} \\
\iff&amp; \sum_{i = 1}^{n} \widetilde{x}_i^{(t)} = n \mu^{(t + 1)} \\
\iff&amp; \mu^{(t + 1)} = \frac{1}{n} \sum_{i = 1}^{n} \widetilde{x}_i^{(t)} =: \overline{\widetilde{x}}^{(t)}
\end{align*}\]</span>
<p>See <a href="matrix_derivatives.html">here</a> for matrix derivatives. Differentiating <span class="math inline">\(Q(\theta \text{ | } \theta^{(t)})\)</span> with respect to <span class="math inline">\(\Sigma^{-1}\)</span> yields:</p>
<span class="math display">\[\begin{align*}
\nabla_{\Sigma^{-1}} Q(\theta \text{ | } \theta^{(t)}) &amp;= \sum_{i = 1}^{n} \nabla_{\Sigma^{-1}} Q_i (\theta \text{ | } \theta^{(t)}) \\
&amp;= \sum_{i = 1}^{n} \frac{1}{2} \nabla_{\Sigma^{-1}} \log |\Sigma^{-1}| - \frac{1}{2} \nabla_{\Sigma^{-1}} \text{tr} \big( (\Sigma^{-1})_{M_i M_i} \Sigma_{M_i M_i \cdot O_i}^{(t)} \big) \\
&amp;\hspace{10pt} - \sum_{i = 1}^{n} \frac{1}{2} \nabla_{\Sigma^{-1}} (\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \\
&amp;= \frac{1}{2} \sum_{i = 1}^{n} \nabla_{\Sigma^{-1}} \log |\Sigma^{-1}| - \nabla_{\Sigma^{-1}} \text{tr} \big( (\Sigma^{-1})_{M_i M_i} \Sigma_{M_i M_i \cdot O_i}^{(t)} \big) \\
&amp;\hspace{10pt} - \frac{1}{2} \sum_{i = 1}^{n} \nabla_{\Sigma^{-1}} \text{tr} \big( (\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu) \big)
\end{align*}\]</span>
<p>since <span class="math inline">\((\widetilde{x}_i^{(t)} - \mu)^T \Sigma^{-1} (\widetilde{x}_i^{(t)} - \mu)\)</span> is a constant. Let’s continue:</p>
<span class="math display">\[\begin{align*}
\nabla_{\Sigma^{-1}} Q(\theta \text{ | } \theta^{(t)}) &amp;= \frac{1}{2} \big[ \sum_{i = 1}^{n} \Sigma -  \widetilde{\Sigma}_{i}^{(t)} \big] - \frac{1}{2} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu)(\widetilde{x}_i^{(t)} - \mu)^T \\
&amp;= \frac{1}{2} \big[ n \Sigma - \sum_{i = 1}^{n} \widetilde{\Sigma}_{i}^{(t)} \big] - \frac{1}{2} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu)(\widetilde{x}_i^{(t)} - \mu)^T
\end{align*}\]</span>
<p>where <span class="math inline">\(\widetilde{\Sigma}_i^{(t)}\)</span> is a <span class="math inline">\(p \times p\)</span> matrix having zero everywhere except <span class="math inline">\(M_i M_i\)</span> component replaced by <span class="math inline">\(\Sigma_{M_i M_i \cdot O_i}^{(t)}\)</span>.</p>
<p>The maximizer <span class="math inline">\(\theta^{(t + 1)} = (\mu^{(t + 1)}, \Sigma^{(t + 1)})\)</span> should satisfy: <span class="math display">\[\nabla_{\Sigma^{-1}} Q(\theta^{(t + 1)} \text{ | } \theta^{(t)}) = O\]</span> That is:</p>
<span class="math display">\[\begin{align*}
O &amp;= \frac{1}{2} \big[ n \Sigma^{(t + 1)} - \sum_{i = 1}^{n} \widetilde{\Sigma}_{i}^{(t)} \big] - \frac{1}{2} \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)})(\widetilde{x}_i^{(t)} - \mu^{(t + 1)})^T \\
&amp;= \big[ n \Sigma^{(t + 1)} - \sum_{i = 1}^{n} \widetilde{\Sigma}_{i}^{(t)} \big] - \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)})(\widetilde{x}_i^{(t)} - \mu^{(t + 1)})^T \\
\iff n \Sigma^{(t + 1)} &amp;= \sum_{i = 1}^{n} \widetilde{\Sigma}_{i}^{(t)} + \sum_{i = 1}^{n} (\widetilde{x}_i^{(t)} - \mu^{(t + 1)})(\widetilde{x}_i^{(t)} - \mu^{(t + 1)})^T \\
\iff \Sigma^{(t + 1)} &amp;= \frac{1}{n} \sum_{i = 1}^{n} \Big[ \widetilde{\Sigma}_{i}^{(t)} + (\widetilde{x}_i^{(t)} - \mu^{(t + 1)})(\widetilde{x}_i^{(t)} - \mu^{(t + 1)})^T \Big]
\end{align*}\]</span>
<p>Therefore, the maximizers are:</p>
<span class="math display">\[\begin{align*}
\mu^{(t + 1)} &amp;= \overline{\widetilde{x}}^{(t)} = \frac{1}{n}\sum_{i = 1}^{n} \widetilde{x}_i^{(t)} \\
\Sigma^{(t + 1)} &amp;= \frac{1}{n} \sum_{i = 1}^{n} \big[ (\widetilde{x}_i^{(t)} - \mu^{(t + 1)})(\widetilde{x}_i^{(t)} - \mu^{(t + 1)})^T + \widetilde{\Sigma}_i^{(t)} \big]
\end{align*}\]</span>
<p>With <span class="math inline">\(\theta^{(t + 1)} = (\mu^{(t + 1)}, \Sigma^{(t + 1)})\)</span>, repeat E-step and M-step until convergence. We can test the convergence by either:</p>
<ul>
<li>checking the log-likelihood <span class="math inline">\(Q(\theta \text{ | } \theta^{(t)})\)</span> and the amount of increase; if it does not increase by more than a certain threshold, claim the convergence.</li>
<li>checking some sort of metric <span class="math inline">\(d(\mu^{(t + 1)}, \mu^{(t)})\)</span> and <span class="math inline">\(d(\Sigma^{(t + 1)}, \Sigma^{(t)})\)</span> (e.g. <span class="math inline">\(L_2\)</span>-norm); if both of them are close to <span class="math inline">\(0\)</span>, claim the convergence.</li>
</ul>
<p>The second method works because for every <span class="math inline">\(s\)</span>, <span class="math inline">\(\mu^{(s)}\)</span> and <span class="math inline">\(\Sigma^{(s)}\)</span> are elements of a complete space (in particular, <span class="math inline">\(\mathbb{R}^{p}\)</span> and <span class="math inline">\(\mathbb{R}^{p \times p}\)</span>). In a complete space, a sequence converges if and only if it is Cauchy, and both of <span class="math inline">\(\{ d(\mu^{(t + 1)}, \mu^{(t)}) \}_{t = 0}^{\infty}\)</span> and <span class="math inline">\(\{ d(\Sigma^{(t + 1)}, \Sigma^{(t)})\}_{t = 0}^{\infty}\)</span> are Cauchy sequences.</p>
</div>
</div>
<div id="simulating-nas" class="section level2">
<h2>Simulating <code>NA</code>s</h2>
<p>We shall start with generating multivariate normal iid samples <span class="math inline">\(X_i \stackrel{iid}{\sim} N_p(\mu, \Sigma)\)</span>, where:</p>
<ul>
<li><span class="math inline">\(n = 400\)</span></li>
<li><span class="math inline">\(p = 3\)</span></li>
<li><span class="math inline">\(\mu = (1, 2, 6)\)</span></li>
<li><span class="math inline">\(\Sigma = \begin{bmatrix} 118 &amp; 62 &amp; 44 \\ 62 &amp; 49 &amp; 17 \\ 44 &amp; 17 &amp; 21 \end{bmatrix}\)</span></li>
</ul>
<p>All of these quantities are chosen randomly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1024</span>)
mu &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">6</span>)
Sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">118</span>, <span class="dv">62</span>, <span class="dv">44</span>, <span class="dv">62</span>, <span class="dv">49</span>, <span class="dv">17</span>, <span class="dv">44</span>, <span class="dv">17</span>, <span class="dv">21</span>), <span class="dt">nrow =</span> <span class="dv">3</span>)
n &lt;-<span class="st"> </span><span class="dv">400</span>
X_truth &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> n, <span class="dt">mu =</span> mu, <span class="dt">Sigma =</span> Sigma)</code></pre></div>
<p><code>X_truth</code> stores a complete data.</p>
<p>We will then manually set some components in each <span class="math inline">\(X_i\)</span> to be <code>NA</code> so that the proportion of missing components in a dataset is approximately <code>na_rate</code>, where <code>na_rate</code> is some value the user can specify. Note that we need to make sure not all coordinates in <span class="math inline">\(X_i\)</span> are <code>NA</code>’s:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simulate_na &lt;-<span class="st"> </span><span class="cf">function</span>(X_complete, na_rate) {
    <span class="co"># X_complete: a data frame or a matrix with no NA&#39;s</span>
    <span class="co"># na_rate: a number in (0, 1)</span>
    
    <span class="co"># Create C matrix; entry is FALSE if missing, and TRUE if observed</span>
    nr &lt;-<span class="st"> </span><span class="kw">nrow</span>(X_complete); nc &lt;-<span class="st"> </span><span class="kw">ncol</span>(X_complete)
    C &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">runif</span>(nr <span class="op">*</span><span class="st"> </span>nc) <span class="op">&gt;</span><span class="st"> </span>na_rate, <span class="dt">nrow =</span> nr)
    
    <span class="co"># Check for which i&#39;s we have all components become missing</span>
    checker &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">rowSums</span>(C) <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) 
    <span class="cf">if</span> (<span class="kw">length</span>(checker) <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {
        <span class="co"># Every X_i has at least one component that is observed, </span>
        <span class="co"># which is what we want</span>
        X_complete[<span class="op">!</span>C] &lt;-<span class="st"> </span><span class="ot">NA</span>
    } <span class="cf">else</span> {
        <span class="co"># Otherwise, randomly &quot;revive&quot; some components in such X_i&#39;s</span>
        <span class="cf">for</span> (i <span class="cf">in</span> checker) {
            C[i, <span class="kw">sample</span>(nc, <span class="kw">ceiling</span>(<span class="kw">runif</span>(<span class="dv">1</span>, <span class="dt">max =</span> nc)))] &lt;-<span class="st"> </span><span class="ot">TRUE</span>
        }
        X_complete[<span class="op">!</span>C] &lt;-<span class="st"> </span><span class="ot">NA</span>
    }
    <span class="kw">list</span>(
        <span class="dt">X =</span> X_complete, 
        <span class="dt">C =</span> C,
        <span class="dt">na_rate =</span> na_rate, 
        <span class="dt">na_rate_actual =</span> <span class="kw">sum</span>(<span class="op">!</span>C) <span class="op">/</span><span class="st"> </span>(nr <span class="op">*</span><span class="st"> </span>nc)
    )
}</code></pre></div>
<p>I will set <code>na_rate</code> to be <span class="math inline">\(.4\)</span>, a completely arbitrary choice:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">simulate_na</span>(X_truth, <span class="dt">na_rate =</span> .<span class="dv">4</span>)
X &lt;-<span class="st"> </span>result<span class="op">$</span>X</code></pre></div>
<p><code>X</code> is the data with missing components.</p>
<p>Since we always require <span class="math inline">\(|M_i| &lt; n\)</span> for all <span class="math inline">\(i\)</span> (and thereby randomly “reviving” some values in <code>simulate_na</code>), we will almost always see <code>na_rate_actual</code> being less than <code>na_rate</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result<span class="op">$</span>na_rate_actual</code></pre></div>
<pre><code>## [1] 0.3433333</code></pre>
<p>It is possible to add some correction measure to make <code>na_rate_actual</code> closer to <code>na_rate</code>, but I won’t do that in this note. It just seems unnecessary.</p>
</div>
<div id="imputing-nas" class="section level2">
<h2>Imputing <code>NA</code>s</h2>
<p>Now, let’s impute.</p>
<p>We start with <span class="math inline">\(\mu^{(0)}\)</span> and <span class="math inline">\(\Sigma^{(0)}\)</span> as sample mean and (unbiased) sample variance of observed <span class="math inline">\(X_i\)</span>’s. If <span class="math inline">\(\Sigma^{(0)}\)</span> returns <code>NA</code> values in its entries (which happens if every <span class="math inline">\(X_i\)</span> has at least one component missing), then we will take <span class="math inline">\(\Sigma^{(0)} = \text{diag}(S_1^2, S_2^2, \dots, S_p^2)\)</span>, where <span class="math inline">\(S_j^2\)</span>’s are computed with <code>NA</code> values being omitted in each <span class="math inline">\(j\)</span><sup>th</sup> column.</p>
<p>We then compute the conditional mean and variance of <span class="math inline">\(X_{i M_i}\)</span> given <span class="math inline">\((X_{i O_i}, \theta^{(0)})\)</span>, impute the conditional mean into <span class="math inline">\(X_{i M_i}\)</span>, and update <span class="math inline">\(\theta\)</span> into <span class="math inline">\(\theta^{(1)} = (\mu^{(1)}, \Sigma^{(1)})\)</span>. We continue doing this until either:</p>
<ul>
<li><span class="math inline">\(t =\)</span> <code>max_iter</code> is met, or</li>
<li><span class="math inline">\(||\mu^{(t - 1)} - \mu^{(t)}||_2 &lt;\)</span> <code>eps</code> and <span class="math inline">\(||\Sigma^{(t - 1)} - \Sigma^{(t)}||_2 &lt;\)</span> <code>eps</code> are both satisfied.</li>
</ul>
<p>As a side note, the <span class="math inline">\(L_2\)</span>-norm of a square matrix <span class="math inline">\(A\)</span> is the square root of the largest eigenvalue of <span class="math inline">\(A^T A\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">impute_em &lt;-<span class="st"> </span><span class="cf">function</span>(X, <span class="dt">max_iter =</span> <span class="dv">3000</span>, <span class="dt">eps =</span> <span class="fl">1e-08</span>) {
    <span class="co"># X: a data frame or a matrix, possibly with some NA&#39;s</span>
    <span class="co"># max_iter: a natural number; 3000 by default</span>
    <span class="co"># eps: a positive real number; 1e-08 by default</span>
    
    nr &lt;-<span class="st"> </span><span class="kw">nrow</span>(X)
    nc &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
    C &lt;-<span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(X) <span class="co"># the C matrix</span>
    
    <span class="co"># Collect M_i and O_i&#39;s</span>
    Ms &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="dv">1</span><span class="op">:</span>nc <span class="op">*</span><span class="st"> </span><span class="kw">t</span>(<span class="op">!</span>C))
    Os &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="dv">1</span><span class="op">:</span>nc <span class="op">*</span><span class="st"> </span><span class="kw">t</span>(C))
    M &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span>nr, <span class="cf">function</span>(d) {Ms[d, ][Ms[d, ] <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>]})
    O &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span>nr, <span class="cf">function</span>(d) {Os[d, ][Os[d, ] <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>]})
    
    <span class="co"># Generate Mu_0 and Sigma_0</span>
    Mu &lt;-<span class="st"> </span><span class="kw">colMeans</span>(X, <span class="dt">na.rm =</span> T)
    S &lt;-<span class="st"> </span><span class="kw">var</span>(X, <span class="dt">na.rm =</span> T)
    <span class="cf">if</span> (<span class="kw">is.na</span>(<span class="kw">sum</span>(S))) { <span class="co"># S contains at least one NA</span>
        S &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">apply</span>(X, <span class="dv">2</span>, var, <span class="dt">na.rm =</span> T))
    }
    Mu_tilde &lt;-<span class="st"> </span>S_tilde &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>, <span class="dt">length =</span> nr)
    X_tilde &lt;-<span class="st"> </span>X
    no_conv &lt;-<span class="st"> </span>T
    iter &lt;-<span class="st"> </span><span class="dv">0</span>
    <span class="cf">while</span> (no_conv <span class="op">&amp;</span><span class="st"> </span>iter <span class="op">&lt;</span><span class="st"> </span>max_iter) {
        <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nr) {
            S_tilde[[i]] &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>, nc<span class="op">^</span><span class="dv">2</span>), <span class="dt">nrow =</span> nc)
            <span class="cf">if</span> (<span class="kw">length</span>(O[[i]]) <span class="op">!=</span><span class="st"> </span>nc) { <span class="co"># consider only nonempty M[[i]]&#39;s</span>
                S_MM &lt;-<span class="st"> </span>S[M[[i]], M[[i]]]
                S_MO &lt;-<span class="st"> </span><span class="kw">matrix</span>(S[M[[i]], O[[i]]], <span class="dt">nrow =</span> <span class="kw">length</span>(M[[i]]))
                S_OM &lt;-<span class="st"> </span><span class="kw">t</span>(S_MO)
                S_OO &lt;-<span class="st"> </span>S[O[[i]], O[[i]]]
                Mu_tilde[[i]] &lt;-<span class="st"> </span>Mu[M[[i]]] <span class="op">+</span><span class="st"> </span>
<span class="st">                    </span>S_MO <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>(S_OO) <span class="op">%*%</span><span class="st"> </span>(X[i, O[[i]]] <span class="op">-</span><span class="st"> </span>Mu[O[[i]]])
                X_tilde[i, M[[i]]] &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(Mu_tilde[[i]])
                S_MM.O &lt;-<span class="st"> </span>S_MM <span class="op">-</span><span class="st"> </span>S_MO <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>(S_OO) <span class="op">%*%</span><span class="st"> </span>S_OM
                zero_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>, nc<span class="op">^</span><span class="dv">2</span>), <span class="dt">nrow =</span> nc)
                zero_matrix[M[[i]], M[[i]]] &lt;-<span class="st"> </span>S_MM.O
                S_tilde[[i]] &lt;-<span class="st"> </span>zero_matrix
            }
        }
        Mu_new &lt;-<span class="st"> </span><span class="kw">colMeans</span>(X_tilde)
        S_new &lt;-<span class="st"> </span>((nr <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>nr) <span class="op">*</span><span class="st"> </span><span class="kw">var</span>(X_tilde) <span class="op">+</span><span class="st"> </span><span class="kw">Reduce</span>(<span class="st">&#39;+&#39;</span>, S_tilde) <span class="op">/</span><span class="st"> </span>nr
        no_conv &lt;-<span class="st"> </span><span class="op">!</span>(
            <span class="kw">norm</span>(Mu <span class="op">-</span><span class="st"> </span>Mu_new, <span class="dt">type =</span> <span class="st">&#39;2&#39;</span>) <span class="op">&lt;</span><span class="st"> </span>eps <span class="op">&amp;&amp;</span><span class="st"> </span>
<span class="st">                </span><span class="kw">norm</span>(S <span class="op">-</span><span class="st"> </span>S_new, <span class="dt">type =</span> <span class="st">&#39;2&#39;</span>) <span class="op">&lt;</span><span class="st"> </span>eps
        )
        Mu &lt;-<span class="st"> </span>Mu_new
        S &lt;-<span class="st"> </span>S_new
        iter &lt;-<span class="st"> </span>iter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
    }
    <span class="kw">list</span>(<span class="dt">mu =</span> Mu, <span class="dt">Sigma =</span> S, <span class="dt">X_imputed =</span> X_tilde, <span class="dt">C =</span> C, <span class="dt">iter =</span> iter)
}</code></pre></div>
<p>The higher the <code>max_iter</code> and/or the lower the <code>eps</code> in <code>impute_em</code>, the more accurate the parameter estimates become.</p>
<p>At last, we can impute the missing components:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_imputed &lt;-<span class="st"> </span><span class="kw">impute_em</span>(X)</code></pre></div>
<p>How does the estimated parameters look like? Here are comparisons with the true values:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_imputed<span class="op">$</span>mu <span class="co"># estimate using the imputed data</span></code></pre></div>
<pre><code>## [1] 0.6869754 1.9737023 5.8867824</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu <span class="co"># truth</span></code></pre></div>
<pre><code>## [1] 1 2 6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_imputed<span class="op">$</span>Sigma <span class="co"># estimate using the imputed data</span></code></pre></div>
<pre><code>##           [,1]     [,2]     [,3]
## [1,] 121.45517 68.16616 45.71823
## [2,]  68.16616 54.65531 19.27075
## [3,]  45.71823 19.27075 21.92296</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Sigma <span class="co"># truth</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]  118   62   44
## [2,]   62   49   17
## [3,]   44   17   21</code></pre>
<p>This is interesting. While the parameters of <code>mu</code> are underestimed, the parameters of <code>Sigma</code> are overestimated. We shall check if this is a mere coincidence in the next section.</p>
<p>Here’s how the first six rows of <code>X</code> have been imputed:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(X) <span class="co"># data with missing components</span></code></pre></div>
<pre><code>##            [,1]       [,2]       [,3]
## [1,]         NA  -8.451185         NA
## [2,]         NA         NA  9.2563177
## [3,] -20.795378 -12.621417  1.0554090
## [4,]  -9.818160  -4.273634         NA
## [5,]   5.106661   1.925457         NA
## [6,]         NA -14.007992 -0.6723725</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(result_imputed<span class="op">$</span>X_imputed) <span class="co"># imputed data</span></code></pre></div>
<pre><code>##            [,1]       [,2]       [,3]
## [1,] -12.314954  -8.451185  2.2111026
## [2,]   7.713817   4.935596  9.2563177
## [3,] -20.795378 -12.621417  1.0554090
## [4,]  -9.818160  -4.273634  2.0693288
## [5,]   5.106661   1.925457  8.5356502
## [6,] -20.570105 -14.007992 -0.6723725</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(X_truth) <span class="co"># truth</span></code></pre></div>
<pre><code>##            [,1]       [,2]       [,3]
## [1,]  -4.690880  -8.451185  4.3832914
## [2,]  -1.869142  -5.782317  9.2563177
## [3,] -20.795378 -12.621417  1.0554090
## [4,]  -9.818160  -4.273634  3.1777676
## [5,]   5.106661   1.925457  5.5076653
## [6,] -20.481210 -14.007992 -0.6723725</code></pre>
<p>Some components are close to the true value, and the others are not so much. For example, The entry <code>[1, 1]</code> is imputed with the value -12.3149535, but the true value is -4.69088.</p>
</div>
</div>
<div id="performance" class="section level1">
<h1>3. Performance</h1>
<p>I will take <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\Sigma_{11}\)</span> as representatives. Let’s look at how the estimates of these two change as <code>na_rate</code> increases. The following quantities are to be compared:</p>
<ul>
<li>the estimates using imputed data</li>
<li>the estimates using only observed data</li>
<li>the true parameters
<ul>
<li>In our case, <span class="math inline">\(\mu_1 = 1\)</span> and <span class="math inline">\(\Sigma_{11} = 118\)</span></li>
</ul></li>
</ul>
<p>For different realizations of data with the same parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, we will collect estimates computed by imputed data and observed data at each level of <code>na_rate</code>. MLEs will be computed for observed data rather than unbiased estimates.</p>
<p>20 different datasets are used to produce the plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()
<span class="kw">set.seed</span>(<span class="dv">2048</span>)
number_of_datasets &lt;-<span class="st"> </span><span class="dv">20</span>
nds &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>number_of_datasets
lst_tbl_estimates &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>, number_of_datasets)

<span class="cf">for</span> (j <span class="cf">in</span> nds) {
    <span class="co"># Generate a new data using the same parameters</span>
    X_truth2 &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> n, <span class="dt">mu =</span> mu, <span class="dt">Sigma =</span> Sigma)
    
    <span class="co"># MLEs when nothing missing (i.e. na_rate == 0)</span>
    mu_1_imp &lt;-<span class="st"> </span>mu_1_obs &lt;-<span class="st"> </span><span class="ot">NULL</span>
    sigma_11_imp &lt;-<span class="st"> </span>sigma_11_obs &lt;-<span class="st"> </span><span class="ot">NULL</span>
    mles &lt;-<span class="st"> </span><span class="kw">impute_em</span>(X_truth2)
    mu_1_imp[<span class="dv">1</span>] &lt;-<span class="st"> </span>mu_1_obs[<span class="dv">1</span>] &lt;-<span class="st"> </span>mles<span class="op">$</span>mu[<span class="dv">1</span>]
    sigma_11_imp[<span class="dv">1</span>] &lt;-<span class="st"> </span>sigma_11_obs[<span class="dv">1</span>] &lt;-<span class="st"> </span>mles<span class="op">$</span>S[<span class="dv">1</span>, <span class="dv">1</span>]
    
    <span class="co"># Collect estimates when na_rate &gt; 0</span>
    na_rates &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, .<span class="dv">5</span>, <span class="dt">by =</span> .<span class="dv">005</span>)
    len_rates &lt;-<span class="st"> </span><span class="kw">length</span>(na_rates)
    na_rates_actual &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, len_rates)
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>len_rates) { <span class="co"># Since na_rates[1] == 0, a placeholder</span>
        <span class="co"># Produce NA&#39;s in data</span>
        result_sim &lt;-<span class="st"> </span><span class="kw">simulate_na</span>(X_truth2, na_rates[i])
        na_rates_actual[i] &lt;-<span class="st"> </span>result_sim<span class="op">$</span>na_rate_actual
        
        <span class="co"># Collect estimates based on only observed data</span>
        mu_1_obs[i] &lt;-<span class="st"> </span><span class="kw">colMeans</span>(result_sim<span class="op">$</span>X, <span class="dt">na.rm =</span> T)[<span class="dv">1</span>]
        sigma_11_obs[i] &lt;-<span class="st"> </span>((n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n) <span class="op">*</span><span class="st"> </span><span class="kw">var</span>(result_sim<span class="op">$</span>X[, <span class="dv">1</span>], <span class="dt">na.rm =</span> T)
        
        <span class="co"># Collect estimates based on imputed data</span>
        result_sim_imputed &lt;-<span class="st"> </span><span class="kw">impute_em</span>(result_sim<span class="op">$</span>X)
        mu_1_imp[i] &lt;-<span class="st"> </span>result_sim_imputed<span class="op">$</span>mu[<span class="dv">1</span>]
        sigma_11_imp[i] &lt;-<span class="st"> </span>result_sim_imputed<span class="op">$</span>S[<span class="dv">1</span>, <span class="dv">1</span>]
    }

    <span class="co"># Format a tibble for plotting, using na_rates_actual as x-axis</span>
    lst_tbl_estimates[[j]] &lt;-<span class="st"> </span><span class="kw">tibble</span>(
        na_rates,
        na_rates_actual,
        <span class="dt">dataset =</span> <span class="kw">rep</span>(j, len_rates),
        <span class="st">`</span><span class="dt">mu_1-Truth</span><span class="st">`</span> =<span class="st"> </span><span class="kw">rep</span>(mu[<span class="dv">1</span>], len_rates),
        <span class="st">`</span><span class="dt">sigma_11-Truth</span><span class="st">`</span> =<span class="st"> </span><span class="kw">rep</span>(Sigma[<span class="dv">1</span>, <span class="dv">1</span>], len_rates),
        <span class="st">`</span><span class="dt">mu_1-Observed data</span><span class="st">`</span> =<span class="st"> </span>mu_1_obs,
        <span class="st">`</span><span class="dt">sigma_11-Observed data</span><span class="st">`</span> =<span class="st"> </span>sigma_11_obs,
        <span class="st">`</span><span class="dt">mu_1-Imputed data</span><span class="st">`</span> =<span class="st"> </span>mu_1_imp,
        <span class="st">`</span><span class="dt">sigma_11-Imputed data</span><span class="st">`</span> =<span class="st"> </span>sigma_11_imp
    ) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">gather</span>(key, value, <span class="op">-</span>(na_rates<span class="op">:</span>dataset)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&#39;params_dummy&#39;</span>, <span class="st">&#39;estimates_dummy&#39;</span>), <span class="dt">sep =</span> <span class="st">&#39;-&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">params =</span> params_dummy, <span class="dt">estimates =</span> estimates_dummy) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">unite</span>(grouping_var, params_dummy, estimates_dummy, dataset)
}
all_tbl_estimates &lt;-<span class="st"> </span><span class="kw">Reduce</span>(<span class="st">&#39;rbind&#39;</span>, lst_tbl_estimates)
end &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()</code></pre></div>
<p>Creating <code>all_tbl_estimates</code> takes a while:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">end <span class="op">-</span><span class="st"> </span>start</code></pre></div>
<pre><code>## Time difference of 32.03333 mins</code></pre>
<p>I am providing a link to the <a href="../../files/all_tbl_estimates.csv">csv file</a> that stores all of the information in <code>all_tbl_estimates</code>.</p>
<p>This is how <code>all_tbl_estimates</code> looks like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(all_tbl_estimates)</code></pre></div>
<pre><code>## Observations: 12,120
## Variables: 6
## $ na_rates        &lt;dbl&gt; 0.000, 0.005, 0.010, 0.015, 0.020, 0.025, 0.03...
## $ na_rates_actual &lt;dbl&gt; 0.00000000, 0.00250000, 0.01250000, 0.01250000...
## $ grouping_var    &lt;chr&gt; &quot;mu_1_Truth_1&quot;, &quot;mu_1_Truth_1&quot;, &quot;mu_1_Truth_1&quot;...
## $ value           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
## $ params          &lt;chr&gt; &quot;mu_1&quot;, &quot;mu_1&quot;, &quot;mu_1&quot;, &quot;mu_1&quot;, &quot;mu_1&quot;, &quot;mu_1&quot;...
## $ estimates       &lt;chr&gt; &quot;Truth&quot;, &quot;Truth&quot;, &quot;Truth&quot;, &quot;Truth&quot;, &quot;Truth&quot;, &quot;...</code></pre>
<ul>
<li><code>na_rates</code> is the specified proportion of <code>NA</code>’s in <code>simulate_na</code>.</li>
<li><code>na_rates_actual</code> is the actual proportion of <code>NA</code>’s in the data which is going to be the x-axis</li>
<li><code>grouping_var</code> is the grouping variable to ensure that dots that come from the same dataset are connected. For example, we don’t want dots from the third dataset and the fifth dataset to be connected in a plot. The element in this column is designed to indicate the following information:
<ul>
<li>characters before the second underscore corresponds to <code>params</code> in the same row</li>
<li>characters after the second underscore and before the third underscore corresponds to <code>estimates</code> in the same row</li>
<li>digits after the third underscore represents the dataset the <code>value</code> in the same row is computed from.</li>
</ul></li>
<li><code>value</code> is the union of true values and the estimates, which is going to work as the y-axis</li>
<li><code>params</code> is the facetting variable that will split plot into the plot for <code>mu_1</code> and <code>sigma_11</code></li>
<li><code>estimates</code> is the colouring variable that will colour according to the nature of values in <code>value</code>. There will be three colours for each of these:
<ul>
<li>the estimates computed by imputed data</li>
<li>the estimates computed by observed data</li>
<li>the true parameters</li>
</ul></li>
</ul>
<p>The moment of truth:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_tbl_estimates <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates_actual, <span class="dt">y =</span> value, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> grouping_var), <span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>params, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Missing rate&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;Estimates&#39;</span>, <span class="dt">col =</span> <span class="st">&quot;Based on&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)</code></pre></div>
<p><img src="em_imputation_files/figure-html/testing_plot-1.png" style="display: block; margin: auto;" /></p>
<p>That looks messy. Let’s get rid of <code>geom_line()</code> and look at the points only:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_tbl_estimates <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates_actual, <span class="dt">y =</span> value, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">    </span><span class="co"># geom_line(aes(group = grouping_var), alpha = .3) +</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>params, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Missing rate&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;Estimates&#39;</span>, <span class="dt">col =</span> <span class="st">&quot;Based on&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)</code></pre></div>
<p><img src="em_imputation_files/figure-html/testing_plot2-1.png" style="display: block; margin: auto;" /></p>
<p>The plot reveals a fanning effect in observed-data estimates. That is, the estimates spread out more as missing rate increases. A fanning effect in imputed-data estimates is not as evident as in the observed data. See the plot below for a split view:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g_<span class="dv">1</span> &lt;-<span class="st"> </span>all_tbl_estimates <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(estimates <span class="op">!=</span><span class="st"> &#39;Truth&#39;</span> <span class="op">&amp;</span><span class="st"> </span>params <span class="op">==</span><span class="st"> &#39;mu_1&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates_actual, <span class="dt">y =</span> value, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_line</span>(<span class="dt">y =</span> mu[<span class="dv">1</span>], <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">facet_wrap</span>(params <span class="op">~</span><span class="st"> </span>estimates, <span class="dt">nrow =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;&#39;</span>, <span class="dt">col =</span> <span class="st">&quot;Based on&quot;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)
g_<span class="dv">2</span> &lt;-<span class="st"> </span>all_tbl_estimates <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(estimates <span class="op">!=</span><span class="st"> &#39;Truth&#39;</span> <span class="op">&amp;</span><span class="st"> </span>params <span class="op">==</span><span class="st"> &#39;sigma_11&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates_actual, <span class="dt">y =</span> value, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_line</span>(<span class="dt">y =</span> Sigma[<span class="dv">1</span>, <span class="dv">1</span>], <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">facet_wrap</span>(params <span class="op">~</span><span class="st"> </span>estimates, <span class="dt">nrow =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Missing rate&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;&#39;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;none&#39;</span>)
<span class="kw">grid.arrange</span>(g_<span class="dv">1</span>, g_<span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="em_imputation_files/figure-html/plot2_1-1.png" style="display: block; margin: auto;" /></p>
<p>Let’s now look at lines to see how the estimates change as missing rate increases:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_tbl_estimates <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates_actual, <span class="dt">y =</span> value, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">    </span><span class="co"># geom_point(alpha = .35) +</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> grouping_var), <span class="dt">alpha =</span> .<span class="dv">3</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>params, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Missing rate&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;Estimates&#39;</span>, <span class="dt">col =</span> <span class="st">&quot;Based on&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)</code></pre></div>
<p><img src="em_imputation_files/figure-html/plot3-1.png" style="display: block; margin: auto;" /></p>
<p>Each line represents a dataset; it connects the estimates that are computed under the same data. One thing we see is that as missing rate increases, both estimates become more sporadic.</p>
<p>Let’s compute the sample variance at each missing rate and see how this quantity changes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_tbl_estimates <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(estimates <span class="op">!=</span><span class="st"> &#39;Truth&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(na_rates, params, estimates) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">vars =</span> <span class="kw">var</span>(value)) <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> na_rates, <span class="dt">y =</span> vars, <span class="dt">col =</span> estimates)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>params, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">scale =</span> <span class="st">&#39;free&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&#39;Missing rate&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;Variance of estimates&#39;</span>, <span class="dt">col =</span> <span class="st">&#39;&#39;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&#39;top&#39;</span>)</code></pre></div>
<p><img src="em_imputation_files/figure-html/plot4-1.png" style="display: block; margin: auto;" /></p>
<p>It makes sense to see higher variance in general in observed data since the number of observation used to compute the estimates for <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\Sigma_{11}\)</span> would be smaller.</p>
</div>
<div id="session-info" class="section level1">
<h1>Session Info</h1>
<p>R session info:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows &gt;= 8 x64 (build 9200)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
## [5] LC_TIME=English_Canada.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] itertools2_0.1.1 tidyr_0.8.3      gganimate_1.0.3  ggplot2_3.1.1   
## [5] dplyr_0.8.1      reticulate_1.12  purrr_0.3.2      rmarkdown_1.12  
## 
## loaded via a namespace (and not attached):
##  [1] prettydoc_0.2.1   progress_1.2.2    tidyselect_0.2.5 
##  [4] xfun_0.7          lattice_0.20-38   colorspace_1.4-1 
##  [7] vctrs_0.1.0       htmltools_0.3.6   yaml_2.2.0       
## [10] utf8_1.1.4        rlang_0.3.4       pillar_1.4.0     
## [13] glue_1.3.1        withr_2.1.2       tweenr_1.0.1     
## [16] plyr_1.8.4        stringr_1.4.0     munsell_0.5.0    
## [19] gtable_0.3.0      evaluate_0.13     labeling_0.3     
## [22] knitr_1.23        fansi_0.4.0       Rcpp_1.0.1       
## [25] readr_1.3.1       scales_1.0.0      backports_1.1.4  
## [28] jsonlite_1.6      farver_1.1.0      gridExtra_2.3    
## [31] hms_0.4.2         png_0.1-7         digest_0.6.18    
## [34] stringi_1.4.3     grid_3.6.0        cli_1.1.0        
## [37] tools_3.6.0       magrittr_1.5      lazyeval_0.2.2   
## [40] tibble_2.1.1      crayon_1.3.4      pkgconfig_2.0.2  
## [43] zeallot_0.1.0     MASS_7.3-51.4     Matrix_1.2-17    
## [46] prettyunits_1.0.2 iterators_1.0.10  assertthat_0.2.1 
## [49] rstudioapi_0.10   R6_2.4.0          compiler_3.6.0</code></pre>
</div>
<div id="related-pages" class="section level1">
<h1>Related pages</h1>
<ul>
<li><a href="matrix_derivatives.html">Justifying matrix derivatives</a></li>
<li><a href="em_imputation_python.html">Imputation using EM: Python implementation</a></li>
</ul>
</div>
</section>

<!-- Footer -->
<!-- Reference: https://holtzy.github.io/Pimp-my-rmd/ -->
&nbsp; <!-- whitespace -->
<hr /> <!-- line -->
<div class="footer">
    <p style="text-align: center;">
        © 2019 Junkyu Park
        <br>
        Powered by the modified <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> of the <a href="https://github.com/yixuan/prettydoc">prettydoc::html_pretty</a> engine
    </p>
            
    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
            
    <!-- Add font awesome icons -->
    <p style="text-align: center;">
        <span style="color: #555555;"><em>joon3216@gmail.com</em></span>
        <br>
        <a href="https://www.facebook.com/asdfzxcvjkl1" class="fa fa-facebook"></a>
        <a href="https://github.com/joon3216" class="fa fa-github"></a>
        <a href="https://linkedin.com/in/asdfzxcvjkl1/" class="fa fa-linkedin"></a>
        <a href="https://twitter.com/joon3216" class="fa fa-twitter"></a>
    </p>
</div>
&nbsp; <!-- whitespace -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
