<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Junkyu Park" />


<title>Multivariate response linear regression</title>

<link href="multivariate_response_files/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="multivariate_response_files/pagedtable-1.1/js/pagedtable.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139050237-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-139050237-1');
</script>
<!-- A new navigation bar style settings -->
<style type="text/css">
    /* at the top */
    #navbar
    {
        position: sticky;
        z-index: 1000; /* new; why: make navbar closest to the observer */
        top: 0;
        left: 0;
        padding: 0; /* old: 10px 25px */
        background: rgba(28, 44, 56, 0.99);
        width: 100%;
        height: 50px;
        box-sizing: border-box;
        border-bottom: 1px solid #EAEAEB;
        transition: .5s;
    }
    #navbar .logo
    {
        float: left;
    }
    #navbar .logo img
    {
        height: 30px;
        /* new: margin; why: so that in header, padding can be 0 */
        /* note: header nav ul li a has margin 20px on left and right, 
        so here I let the right margin of img to be 5px so that it matches
        with the left margin 25px */
        /* edit: 5 to 20px since it looks nicer */
        margin: 10px 20px 10px 25px; 
    }
    #navbar nav
    {
        float: right; /* old: left; why change: to give a more standard look */
        margin: 0 27.5px 0 0;
    }
    #navbar nav ul
    {
        margin: 0;
        padding: 0;
        display: flex;
    
    }
    #navbar nav ul li
    {
        padding: 0;
        list-style: none;
        position: relative;
        /* new: margin and padding; why: header padding is now 0 */
        margin: 0;
        padding: 8.5px 0 8.5px 0;
    }
    /* new; why: texts with arrow on the right gets more space  */
    #navbar nav ul li.sub-menu
    {
        /* why 8.5px: that's the value in header nav ul li padding */
        padding: 8.5px 27.5px 8.5px 0;
        padding-bottom: 12px;
        /* new; why: to make dropdown menu available once the mouse is on the menu item that it belongs, and to not affect other menu items that is not of class sub-menu */
    }
    
    /* new; why: prepare in case of text-align: right */
    /* commented out because news menu is now gone in navbar*/
    /* #navbar nav ul li#news
    {
        padding: 8.5px 0;
        margin: 0;
    } */
    
    /* new; why: this potentially has a different background color */
    #navbar nav ul li#home
    {
        background-color: rgba(21, 92, 148, .9); /* old: rgba(28, 44, 56, 0); */
        border-bottom: 1px solid #EAEAEB;
        margin: 0 0 .5px 0;
    }
    
    #navbar nav ul li.sub-menu:before
    {
        content: '\f0d7'; /* &#9660 ▼ nabla */
        font-family: fontAwesome; /* old: sans-serif */
        font-size: 16pt;
        position: absolute;
        /*line-height: 30px;*/
        color: #ffffff;
        top: 7pt;
        right: 22.5px;
        cursor: pointer;
    }
    #navbar nav ul li.active.sub-menu:before
    {
        content: '\f0d8';  /* &#9650 ▲ Delta */
        font-family: fontAwesome; /* new */
        font-size: 16pt;
        position: absolute;
        color: #666;
        top: 7pt;
        right: 22.5px;
        cursor: pointer;
    }
    #navbar nav ul li ul
    {
        position: absolute;
        left: 0;
        top: 50px; /* controls the box position of dropdown menus */
        background: rgba(57, 143, 209, 0.99);
        display: none;
    }
    #navbar nav ul li.active ul
    {
        display: block;
    }
    
    /* new; why: make dropdown menu box fit to the menu above */
    /* padding: 0; is for slimmer individual dropdown menu items */
    /* old */
    #navbar nav ul li.sub-menu ul li
    {
        display: block;
        width: 200px;
        padding: 5px 0;
    }
    
    /* new: header nav ul li ul li a */
    /* why: giving an indentation */
    #navbar nav ul li ul li a
    {
        margin: 0 40px;
    }
    
    /* header nav ul li#projects.sub-menu ul li
    {
        display: block;
        width: 115px;
        padding: 0;
    }
    header nav ul li#rm.sub-menu ul li
    {
        display: block;
        width: 197px;
        padding: 0;
    } */
    
    #navbar nav ul li a
    {
        height: 30px;
        line-height: 30px;
        padding: 0; /* old: 0 20px, and margin didn't exist; why change: to make text the only clickable object */
        margin: 0 20px;
        color: #ffffff;
        text-decoration: none;
        text-shadow: none; /* new; why: to be compatible with the Tactile theme */
        /*display: block;*/
    }
    
    /* new: news; why add: to make News go to the right */
    /* commented out because the same effect is achieved by having 
    header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
    /* header nav ul li.news
    {
        margin: 0 0 0 20px;
    } */
    
    /* new: rm; why: to make r_m go to the right */
    /* commented out because the same effect is achieved by having 
    header nav ul li.sub-menu padding: 8.5px 15px 8.5px 0; */
    /* header nav ul li#rm
    {
        margin: 0 0 0 20px;
    } */
    
    
    #navbar nav ul li a:hover
    {
        color: #666;
    }
    
    /* new: header nav ul li:hover ul, why: to make dropdown menu appear whenever mouse is above */
    #navbar nav ul li:hover ul
    {
        display: block;
    }
    
    #navbar nav ul li:hover ul li:hover
    {
        background-color: rgba(5, 83, 143, 0.99);
    }
    
    .menu-toggle
    {
        color: #ffffff;
        float: right;
        line-height: 30px;
        font-size: 24px;
        cursor: pointer;
        display: none;
        text-shadow: none;
    }

    ul.social-network
    {
        text-align: center;
        padding: 0;
        margin: 5px 0;
    }

    ul.social-network li
    {
        display: inline;
        list-style: none;
        padding: 0 5px;
    }
    @media (max-width: 800px) /* old1: 991px; old2: 721px */
    {
        /* at the top */
        #navbar
        {
            padding: 0; /* old: 10px 25px */
        }
        .menu-toggle
        {
            display: block;
            margin: 10px 25px /* new; why: header padding is now 0 */
        }
        #navbar nav
        {
            /*display: none;*/
            overflow: auto; /* new; why: when mobile, make sure scroll shows up if vertical space not sufficient to display every element of nav */
            position: absolute;
            width: 100%;
            height: calc(100vh - 50px);
            background: rgba(28, 44, 56, 0.99);
            top: 50px;
            left: -100%;
            transition: .5s;
        }
        #navbar nav.active
        {
            left: 0;
        }
        #navbar nav ul
        {
            display: block;
            /*text-align: center;*/
        }
    
        /* new; why: to make sure it doesn't appear in mobile view;
        I don't want to see it in mobile since the logo already directs you
        to home. Adding home in mobile seems a clutter.
        */
        #navbar nav ul li#home
        {
            display: none;
        }
    
        #navbar nav ul li a
        {
            border-bottom: 1px solid rgba(255, 255, 255, .5);
            height: 50px;
            line-height: 50px;
            padding: 0 20px;
        }
        #navbar nav ul li.active ul
        {
            position: relative;
        }
        #navbar nav ul li ul li
        {
            width: 100%;
        }
    
        /* new: header nav ul li.sub-menu */
        /* why: so that dropdown menus fill the entire row in mobile */
        #navbar nav ul li.sub-menu
        {
            padding: 8.5px 0;
        }
    
        #navbar nav ul li.sub-menu:before
        {
            content: '+'; /* old: &#9660 nabla */
            font-size: 20pt;
            font-family: sans-serif;
            height: 40px;
            position: absolute;
            /* line-height: 30px; */
            color: #ffffff;
            width: 20px;
            /* top: 5pt; */
            right: 25px;
            cursor: pointer;
            bottom: 18px;
        }
        #navbar nav ul li.active.sub-menu:before
        {
            content: '–';  /* new: &#9650 Delta */
            font-size: 20pt;
            /* top: 5pt; */
            right: 25px;
            /* line-height: 30px; */
            cursor: pointer;
            position: absolute;
            color: #666;
            bottom: 18px;
            height: 40px;
        }
        #navbar nav ul li ul
        {
            position: absolute;
            left: 0;
            top: 0px; /* controls the box position of 2018 and 2019 under Research materials */
            background: rgba(57, 143, 209, 0.99);
            display: none;
        }
    
        /* new: hover and active
        why: do not display drop down menus when mouse is over it in mobile, 
        but display them when plus signs are clicked */
        #navbar nav ul li:hover ul
        {
            display: none;
        }
        #navbar nav ul li.active ul
        {
            display: block;
        }
    
        /* new; why: no background color change in dropdown menu when hovering over in mobile */
        #navbar nav ul li.sub-menu:hover ul li:hover
        {
            background-color: rgba(5, 83, 143, 0);
        }
    
        /* new: News; why: to make News align with the others in mobile */
        /* commented out since Research Materials uses different method
        to get more space on its right (header nav ul li.sub-menu padding) */
    
        /* header nav ul li.news
        {
            margin: 0;
        } */
        /* new: rm; why: to make rm align with the others in mobile */
        /* commented out for the same reason */
        /* header nav ul li#rm
        {
            margin: 0;
        } */
    
        /* while scrolling */
        #navbar.black nav ul li a:hover
        {
            color: #666;
        }
    }
    
    /* while scrolling */
    #navbar.black
    {
        background: rgba(21, 92, 148, .9);
    }
    #navbar.black nav ul li#home
    {
        background-color: rgba(28, 44, 56, 0);
        /* border-bottom: 1px solid #EAEAEB;
        margin: 0 0 .5px 0; why commented: unnecessary */
        transition: .2s;
    }
    #navbar.black nav ul li a:hover
    {
        color: darkgrey;
    }
    #navbar.black nav ul li.active.sub-menu:before
    {
        color: darkgrey;
    }
    </style>
    
    <!-- 1. Navigation bar color change as one scrolls -->
    <!-- by adding a new class="black" while scrolling -->
    <script src="https://code.jquery.com/jquery-3.3.1.js"></script>
    <script type="text/javascript">
        $(window).on('scroll', function(){
            if ($(window).scrollTop()){
               navbar.classList.add('black');
               /* old: $('header').addClass('black'); */
            }
            else
            {
                navbar.classList.remove('black');
                /* old: $('header').removeClass('black'); */
            }
        })
    </script>
    
    <!-- 2. Navigation bar slides from the left in mobile -->
    <!-- 3. Only one dropdown menu at a time will appear -->
    <script type="text/javascript">
        $(document).ready(function(){
            $('.menu-toggle').click(function(){
                $('nav').toggleClass('active')
            })
            $('ul li').click(function(){
                $(this).siblings().removeClass('active');
                $(this).toggleClass('active');
            })
        })
    </script>
    
    <!-- Using caret down and up symbols -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
<link rel="icon" href="../../style/all_orange_jp.png">


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

/* A workaround for https://github.com/jgm/pandoc/issues/4278 */
a.sourceLine {
  pointer-events: auto;
}

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link rel="stylesheet" href="multivariate_response_files/style.css" type="text/css" />





</head>

<body>


<!-- A new navigation bar -->
<div id="navbar">
    <div class="logo">
        <a href="../../index.html"><img src="../../style/all_orange_jp.png"></a>
    </div>
    <nav>
        <ul>
            <li id="home">
                <a href="../../index.html">Home</a>
            </li>
            <li class="sub-menu" id="projects">
                <a href="../../projects.html">Projects</a>
                <ul>
                    <li>
                        <a href="../../projects/2019.html">2019</a>
                    </li>
                    <li>
                        <a href="../../projects/2020.html">2020</a>
                    </li>
                </ul>
            </li>
            <li class="sub-menu" id="rm">
                <a href="../../research_materials.html">Research materials</a>
                <ul>
                    <li>
                        <a href="../../research_materials/2018.html">2018</a>
                    </li>
                    <li>
                        <a href="../../research_materials/2019.html">2019</a>
                    </li>
                    <li>
                        <a href="../../research_materials/2020.html">2020</a>
                    </li>
                </ul>
            </li>
            <!-- <li id="news">
                <a href="../../news.html">News</a>
            </li> -->
            <li>
                <a href="../../files/resume_junkyu_park.pdf">Resume</a>
            </li>
        </ul>
    </nav>
    <div class="menu-toggle">
        <i class="fa fa-bars" aria-hidden="true"></i>
    </div>
</div>


<section class="page-header">
<h1 class="title toc-ignore project-name">Multivariate response linear regression</h1>
<h4 class="author project-author">Junkyu Park</h4>
</section>



<section class="main-content">
<p>The following R package is used in this note:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">library</span>(dplyr)</a></code></pre></div>

<div id="TOC" class="toc" style="padding:2rem 2rem 0 0;">
<ul style="list-style:none;">
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#the-model">2. The model</a><ul>
<li><a href="#formulation">Formulation</a></li>
<li><a href="#mles">MLEs</a><ul>
<li><a href="#mle-for-mathbfb">MLE for <span class="math inline">\(\mathbf{B}\)</span></a></li>
<li><a href="#mle-for-sigma">MLE for <span class="math inline">\(\Sigma\)</span></a></li>
</ul></li>
<li><a href="#distributions">Distributions</a><ul>
<li><a href="#hatmathbfb"><span class="math inline">\(\hat{\mathbf{B}}\)</span></a></li>
<li><a href="#hatsigma"><span class="math inline">\(\hat{\Sigma}\)</span></a></li>
</ul></li>
</ul></li>
<li><a href="#an-example-iris">3. An example: <code>iris</code></a></li>
<li><a href="#session-info">Session info</a></li>
<li><a href="#related-page">Related page</a></li>
</ul>
</div>
&nbsp;

<div id="introduction" class="section level1">
<h1>1. Introduction</h1>
<p>The purpose of this note is to understand basics of the linear regression model having a multivariate response. I will compute parameter estimates using maximum likelihood, and the expected values of those estimators. Using <code>iris</code> dataset, we shall see that the model parameters coincide with the case of univariate response. Sum-of-squares decomposition, or inferences on model parameters (hypothesis testing, model comparisons, confidence and prediction regions) is not discussed in this note.</p>
</div>
<div id="the-model" class="section level1">
<h1>2. The model</h1>
<p>Let’s formulate the following notations:</p>
<ul>
<li><span class="math inline">\(e_j\)</span> : a <a href="https://en.wikipedia.org/wiki/Conformable_matrix">conformable</a> vector whose <span class="math inline">\(j\)</span><sup>th</sup> element is <span class="math inline">\(1\)</span> and the rest are <span class="math inline">\(0\)</span></li>
<li><span class="math inline">\(A_{ij} := e_i^T A e_j\)</span> : the <span class="math inline">\((i, j)\)</span><sup>th</sup> entry of <span class="math inline">\(A\)</span>, where <span class="math inline">\(A\)</span> is a matrix</li>
</ul>
<div id="formulation" class="section level2">
<h2>Formulation</h2>
<p>Say the response vector is <span class="math inline">\(Y = (y_1, \dots, y_q)\)</span>. The multivariate linear regression model can be written as:</p>
<p><span class="math display">\[\begin{align*}
Y_i \stackrel{indep}{\sim} N_q (\mathbf{B}^T x_i, \Sigma)
\end{align*}\]</span></p>

<p>where:</p>
<ul>
<li><span class="math inline">\(i = 1, \dots, n\)</span></li>
<li><span class="math inline">\(Y_i = (y_{i1}, \dots, y_{iq})\)</span></li>
<li><span class="math inline">\(x_i\)</span> is a <span class="math inline">\(k-\)</span>dimensional vector of features/predictors, and</li>
<li><span class="math inline">\(\mathbf{B}_{k \times q}\)</span> is a matrix.</li>
</ul>
<p>In other words, the model can be written as: <span class="math display">\[Y_i = \mathbf{B}^T x_i + \mathcal{E}_i \sim N_q(\mathbf{B}^T x_i, \Sigma)\]</span> where <span class="math inline">\(\mathcal{E}_i = (\varepsilon_{i1}, \dots, \varepsilon_{iq}) \stackrel{iid}{\sim} N_{q} (\mathbf{0}, \Sigma)\)</span>. Or, using the fact that <span class="math inline">\(e_j^T Y_i = y_{ij}\)</span> is also normally distributed: <span class="math display">\[y_{ij} = \boldsymbol{\beta}_j^T x_{i} + \varepsilon_{ij} = x_i^T \boldsymbol{\beta}_j + \varepsilon_{ij} \sim N(x_i^T \boldsymbol{\beta}_j, \Sigma_{jj})\]</span> where <span class="math inline">\(\boldsymbol{\beta}_j\)</span> is <span class="math inline">\(j\)</span><sup>th</sup> column of <span class="math inline">\(\mathbf{B} := \Big[ \beta_{pj} \Big]_{k \times q}\)</span>. That is, <strong>the multivariate response linear regression is just the univariate response linear regression on each <span class="math inline">\(y_{j}\)</span>, <span class="math inline">\(j = 1, \dots, q\)</span>, with some extra information about the relationship between parameters</strong> (this will be explained down below). Or, in a compact form: <span class="math display">\[\mathbf{Y} = \mathbf{X} \mathbf{B} + \boldsymbol{\mathcal{E}}\]</span> where: <span class="math display">\[\mathbf{Y} := \begin{bmatrix} Y_1^T \\ \vdots \\ Y_n^T \end{bmatrix} = \Big[ y_{ij} \Big]_{n \times q}, \text{ } \mathbf{X} := \begin{bmatrix} x_1^T \\ \vdots \\ x_n^T \end{bmatrix} = \Big[ x_{ip} \Big]_{n \times k}, \text{ } \boldsymbol{\mathcal{E}} := \begin{bmatrix} \mathcal{E}_1^T \\ \vdots \\ \mathcal{E}_n^T \end{bmatrix} = \Big[ \varepsilon_{ij} \Big]_{n \times q}\]</span></p>
<p>The implication of this model is that:</p>
<ul>
<li>The “true” relationship between <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(x_i\)</span> is linear (and by extension, <span class="math inline">\(y_{ij}\)</span> and <span class="math inline">\(x_i\)</span>), and there are “true” parameters (i.e. the same across all <span class="math inline">\(i\)</span>’s), <span class="math inline">\(\mathbf{B}\)</span> and <span class="math inline">\(\Sigma\)</span>, that describe the relationship.</li>
<li><span class="math inline">\(\mathbf{Y}\)</span> is a linear transformation of <span class="math inline">\(\mathbf{B}\)</span>.</li>
<li>Each observation is independent (since error vectors are assumed to be iid).</li>
<li>Error vectors are normally distributed and homoscedastic.</li>
<li>The model with an intercept is the one whose first elements of <span class="math inline">\(x_i\)</span>’s are all <span class="math inline">\(1\)</span>. Alternatively, it is the one where the first column of <span class="math inline">\(\mathbf{X}\)</span> is <span class="math inline">\(\mathbf{1} = (1, 1, \dots, 1)\)</span>.</li>
</ul>
</div>
<div id="mles" class="section level2">
<h2>MLEs</h2>
<p>We may assume two things:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\Sigma\)</span> is positive-definite so that writing <span class="math inline">\(\Sigma^{-1}\)</span> makes sense</li>
<li><span class="math inline">\((\mathbf{X}^T \mathbf{X})^{-1}\)</span> exists (i.e. features are linearly independent)</li>
</ol>
<p>Say <span class="math inline">\(f(Y_i; x_i, \mathbf{B}, \Sigma)\)</span> is the density of <span class="math inline">\(Y_i\)</span>. The log likelihood is then:</p>
<p><span class="math display">\[\begin{align*}
L (\mathbf{B}, \Sigma; \mathbf{Y}, \mathbf{X}) &amp;= \prod_{i = 1}^{n} f(Y_i; x_i, \mathbf{B}, \Sigma) \\
&amp;= \prod_{i = 1}^{n} (2 \pi)^{- \frac{n}{2}} \det(\Sigma)^{-\frac{1}{2}} \exp \big( -\frac{1}{2} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i) \big) \\
&amp;\propto \det(\Sigma)^{-\frac{n}{2}} \exp \big( -\frac{1}{2} \sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i) \big) \\
\implies \ell (\mathbf{B}, \Sigma; \mathbf{Y}, \mathbf{X}) &amp;:= \ln L (\mathbf{B}, \Sigma; \mathbf{Y}, \mathbf{X}) \\
&amp;\propto -\frac{n}{2} \ln \det (\Sigma) - \frac{1}{2} \sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i) \\
&amp;= -\frac{n}{2} \ln \det (\Sigma) - \frac{1}{2} \text{tr}\big( \sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i) \big)
\end{align*}\]</span></p>
<p>since <span class="math inline">\(\sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i)\)</span> is a constant, and <span class="math inline">\(\text{tr}(c) = c\)</span> for a constant <span class="math inline">\(c\)</span>.</p>
<p>Trace is linear and invariant under cyclic permutations, so:</p>
<p><span class="math display">\[\begin{align*}
&amp;\text{tr}\big( \sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i)^T \Sigma^{-1} (Y_i - \mathbf{B}^T x_i) \big) \\
&amp;= \text{tr}\big( \sum_{i = 1}^{n} \Sigma^{-1} (Y_i - \mathbf{B}^T x_i)  (Y_i - \mathbf{B}^T x_i)^T \big) \\
&amp;= \text{tr}\big(\Sigma^{-1} \sum_{i = 1}^{n}  (Y_i - \mathbf{B}^T x_i)  (Y_i - \mathbf{B}^T x_i)^T \big)
\end{align*}\]</span></p>
<p>Let <span class="math inline">\(C := \sum_{i = 1}^{n} (Y_i - \mathbf{B}^T x_i) (Y_i - \mathbf{B}^T x_i)^T\)</span>. Notice that:</p>
<p><span class="math display">\[\begin{align*}
C &amp;= \sum_{i = 1}^{n}  (Y_i - \mathbf{B}^T x_i)  (Y_i - \mathbf{B}^T x_i)^T \\
&amp;= \sum_{i = 1}^{n}  (Y_i - \mathbf{B}^T x_i)  (Y_i^T - x_i^T \mathbf{B}) \\
&amp;= \sum_{i = 1}^{n}  Y_i Y_i^T - \mathbf{B}^T x_i Y_i^T - Y_i x_i^T \mathbf{B} + \mathbf{B}^T x_i x_i^T \mathbf{B} \\
&amp;= \sum_{i = 1}^{n} Y_i Y_i^T - \mathbf{B}^T \sum_{i = 1}^{n} x_i Y_i^T - \Big[ \sum_{i = 1}^{n} Y_i x_i^T \Big] \mathbf{B} + \mathbf{B}^T \Big[\sum_{i = 1}^{n} x_i x_i^T \Big] \mathbf{B}
\end{align*}\]</span></p>
<p>and also:</p>
<ul>
<li><span class="math inline">\(\sum_{i = 1}^{n} Y_i Y_i^T = \begin{bmatrix} Y_1 &amp; \dots &amp; Y_n \end{bmatrix} \begin{bmatrix} Y_1^T \\ \vdots \\ Y_n^T \end{bmatrix} = \mathbf{Y}^T \mathbf{Y}\)</span></li>
<li><span class="math inline">\(\sum_{i = 1}^{n} x_i Y_i^T = \begin{bmatrix} x_1 &amp; \dots &amp; x_n \end{bmatrix}_{k \times n} \begin{bmatrix} Y_1^T \\ \vdots \\ Y_n^T \end{bmatrix}_{n \times q} = \mathbf{X}^T \mathbf{Y}\)</span></li>
<li><span class="math inline">\(\sum_{i = 1}^{n} Y_i x_i^T = \Big[ \sum_{i = 1}^{n} x_i Y_i^T \Big]^T = \mathbf{Y}^T \mathbf{X}\)</span></li>
<li><span class="math inline">\(\sum_{i = 1}^{n} x_i x_i^T = \mathbf{X}^T \mathbf{X}\)</span> likewise.</li>
</ul>
<p>Define <span class="math inline">\(H := \mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T\)</span> and <span class="math inline">\(\mathbf{B}^* = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\)</span>. Then:</p>
<p><span class="math display">\[\begin{align*}
C &amp;= \mathbf{Y}^T \mathbf{Y} - \mathbf{B}^T \mathbf{X}^T \mathbf{Y} - \mathbf{Y}^T \mathbf{X} \mathbf{B} + \mathbf{B}^T \mathbf{X}^T \mathbf{X} \mathbf{B} \\
&amp;= \mathbf{Y}^T \mathbf{Y} - \mathbf{B}^T \mathbf{X}^T \mathbf{Y} - \mathbf{Y}^T \mathbf{X} \mathbf{B} + \mathbf{B}^T \mathbf{X}^T \mathbf{X} \mathbf{B} + \mathbf{Y}^T H \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \\
&amp;= \mathbf{B}^T \mathbf{X}^T \mathbf{X} \mathbf{B} - \mathbf{Y}^T \mathbf{X} \mathbf{B} - \mathbf{B}^T \underbrace{\mathbf{X}^T \mathbf{Y}}_{=\mathbf{X}^T \mathbf{X} \mathbf{B}^*} + \mathbf{Y}^T \underbrace{H \mathbf{Y}}_{= \mathbf{X} \mathbf{B}^*} + \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \\
&amp;= \big[ \mathbf{B}^T \mathbf{X}^T \mathbf{X} - \mathbf{Y}^T \mathbf{X} \big] \big[ \mathbf{B} - \mathbf{B}^* \big] + \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \\
&amp;= \big[ \mathbf{B}^T - \mathbf{Y}^T \mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1} \big] \mathbf{X}^T \mathbf{X} \big[ \mathbf{B} - \mathbf{B}^* \big] + \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \\
&amp;= (\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*) + \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y}
\end{align*}\]</span></p>
<div id="mle-for-mathbfb" class="section level3">
<h3>MLE for <span class="math inline">\(\mathbf{B}\)</span></h3>
<p>Maximizing <span class="math inline">\(\ell (\mathbf{B}; \Sigma, \mathbf{Y}, \mathbf{X}) \propto -\frac{n}{2} \ln \det(\Sigma) - \frac{1}{2} \text{tr} \big(\Sigma^{-1} C \big)\)</span> with respect to <span class="math inline">\(\mathbf{B}\)</span> is equivalent to minimizing <span class="math inline">\(\text{tr} \big(\Sigma^{-1} C \big)\)</span>, or minimizing: <span class="math display">\[\text{tr}\big(\Sigma^{-1} (\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*)\big)\]</span> because <span class="math inline">\(\mathbf{Y}^T \mathbf{Y}\)</span> and <span class="math inline">\(\mathbf{Y}^T H \mathbf{Y}\)</span> are <span class="math inline">\(\mathbf{B}\)</span>-invariant.</p>
<p>The minimum possible value of this quantity is <span class="math inline">\(0\)</span> because:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*)\)</span> is positive-semidefinite:</li>
</ol>
<p><span class="math display">\[\begin{align*}
(\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*) &amp;= (\mathbf{B} - \mathbf{B}^*)^T (\mathbf{X}^T \mathbf{X})^{\frac{1}{2}} (\mathbf{X}^T \mathbf{X})^{\frac{1}{2}} (\mathbf{B} - \mathbf{B}^*) \\
&amp;= [(\mathbf{X}^T \mathbf{X})^{\frac{1}{2}} (\mathbf{B} - \mathbf{B}^*)]^T [(\mathbf{X}^T \mathbf{X})^{\frac{1}{2}} (\mathbf{B} - \mathbf{B}^*)] \\
&amp;= [U \Lambda V^T]^T [U \Lambda V^T] \\
&amp;= V \Lambda^T \Lambda V^T \text{ } (V \in \mathbb{R}^{q \times q}, \Lambda \in \mathbb{R}^{k \times q}) \\
&amp;= V \text{diag}(\lambda_1^2, \dots, \lambda_q^2) V^T
\end{align*}\]</span></p>
<p>(using singular value decomposition)</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(\Sigma\)</span> is positive-definite, and so is:</li>
</ol>
<p><span class="math display">\[\begin{align*}
\Sigma^{-1} &amp;= W \Lambda^* W^T = \sum_{j = 1}^{q} \lambda_j^* w_j w_j^T \\
&amp;\iff \lambda_j^* &gt; 0 \text{ } \forall j
\end{align*}\]</span></p>
<p>(using spectral decomposition)</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(\text{tr}\big(\Sigma^{-1} (\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*)\big)\)</span> can be written as a sum of quadratic forms:</li>
</ol>
<p><span class="math display">\[\begin{align*}
&amp;\text{tr}\big(\Sigma^{-1} (\mathbf{B} - \mathbf{B}^*)^T \mathbf{X}^T \mathbf{X} (\mathbf{B} - \mathbf{B}^*)\big) \\
&amp;= \text{tr} \Big[ \big( \sum_{j = 1}^{q} \lambda_j^* w_j w_j^T \big) V \Lambda^T \Lambda V^T \Big] \\
&amp;= \sum_{j = 1}^{q} \lambda_j^* \text{tr} \big[w_j w_j^T V \Lambda^T \Lambda V^T \big] \\
&amp;= \sum_{j = 1}^{q} \lambda_j^* \text{tr} \big[w_j^T V \Lambda^T \Lambda V^T w_j \big] \\
&amp;= \sum_{j = 1}^{q} \lambda_j^* w_j^T V \Lambda^T \Lambda V^T w_j
\end{align*}\]</span></p>
<p>since <span class="math inline">\(w_j^T V \Lambda^T \Lambda V^T w_j\)</span> is a constant. Now, we see that <span class="math inline">\(w_j^T V \Lambda^T \Lambda V^T w_j \geq 0\)</span> since <span class="math inline">\(V \Lambda^T \Lambda V^T\)</span> is positive-semidefinite as shown in 1. That is, the quantity we want to minimize can be written as a sum of non-negative numbers. Moreover, we see that <span class="math inline">\(0\)</span> is achieved if (and only if) <span class="math inline">\(\mathbf{B} = \mathbf{B}^*\)</span>. Therefore: <span class="math display">\[\hat{\mathbf{B}} = \mathbf{B}^* = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\]</span> which is the same form as <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> in the univariate case.</p>
</div>
<div id="mle-for-sigma" class="section level3">
<h3>MLE for <span class="math inline">\(\Sigma\)</span></h3>
<p>Refer to <a href="matrix_derivatives.html">matrix derivatives</a> here.</p>
<p><span class="math display">\[\begin{align*}
\ell (\Sigma; \hat{\mathbf{B}}, \mathbf{Y}, \mathbf{X}) &amp;\propto -\frac{n}{2} \ln \det(\Sigma) - \frac{1}{2} \text{tr} \big(\Sigma^{-1} C \big) \\
&amp;= \frac{n}{2} \ln \det(\Sigma^{-1}) - \frac{1}{2} \text{tr} \big(\Sigma^{-1} C \big) \\
\implies \nabla_{\Sigma^{-1}} \ell (\Sigma; \hat{\mathbf{B}}, \mathbf{Y}, \mathbf{X}) &amp;= \frac{n}{2} \cdot \frac{1}{\det(\Sigma^{-1})} \cdot \det(\Sigma^{-1}) [(\Sigma^{-1})^{-1}]^T - \frac{1}{2} C^T \\
&amp;= \frac{n}{2} \Sigma - \frac{1}{2} C \\
&amp;= \frac{n}{2} \Sigma - \frac{1}{2} \Big( \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \Big)
\end{align*}\]</span></p>
<p>since <span class="math inline">\((\hat{\mathbf{B}} - \hat{\mathbf{B}})^T \mathbf{X}^T \mathbf{X} (\hat{\mathbf{B}} - \hat{\mathbf{B}}) = \mathbf{O}_{q \times q}\)</span>. So the maximizer <span class="math inline">\(\hat{\Sigma}\)</span> satisfies: <span class="math display">\[\nabla_{\Sigma^{-1}} \ell (\hat{\Sigma}; \hat{\mathbf{B}}, \mathbf{Y}, \mathbf{X}) = \mathbf{O}\]</span> or:</p>
<p><span class="math display">\[\begin{align*}
&amp;\frac{n}{2} \hat{\Sigma} - \frac{1}{2} \Big( \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} \Big) = \mathbf{O} \\
\implies &amp;n \hat{\Sigma} = \mathbf{Y}^T \mathbf{Y} - \mathbf{Y}^T H \mathbf{Y} = \mathbf{Y}^T (I_n - H) \mathbf{Y} \\
\implies &amp;\therefore \text{ } \hat{\Sigma} = \frac{1}{n} \mathbf{Y}^T (I_n - H) \mathbf{Y}
\end{align*}\]</span></p>
<p>Does it look familiar?</p>
<p><strong>Aside 1</strong>: the total variability in <span class="math inline">\(Y_i\)</span>’s in <span class="math inline">\(\mathbf{Y}\)</span> can be written as the unbiased sample variance of <span class="math inline">\(Y_i\)</span>’s, or:</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n - 1} \sum_{i = 1}^{n} (Y_i - \overline{Y})(Y_i - \overline{Y})^T &amp;= \frac{1}{n - 1} \Big[ \big[ \sum_{i = 1}^{n} Y_i Y_i^T \big] - n \overline{Y} \overline{Y}^T \Big] \\
&amp;= \frac{1}{n - 1} \Big[ \mathbf{Y}^T \mathbf{Y} - n (\frac{1}{n} \mathbf{Y}^T \mathbf{1}_{n \times 1})(\frac{1}{n} \mathbf{Y}^T \mathbf{1}_{n \times 1})^T \Big] \\
&amp;= \frac{1}{n - 1} \Big[ \mathbf{Y}^T \mathbf{Y} - \frac{1}{n} \mathbf{Y}^T \mathbf{1} \mathbf{1}^T \mathbf{Y} \Big] \\
&amp;= \frac{1}{n - 1} \mathbf{Y}^T (I_n - \frac{1}{n} \mathbf{1} \mathbf{1}^T ) \mathbf{Y}
\end{align*}\]</span></p>
<p>Does that also look familiar?</p>
</div>
</div>
<div id="distributions" class="section level2">
<h2>Distributions</h2>
<div id="hatmathbfb" class="section level3">
<h3><span class="math inline">\(\hat{\mathbf{B}}\)</span></h3>
<p>First, note that <span class="math inline">\(\hat{\mathbf{B}}\)</span> is unbiased:</p>
<p><span class="math display">\[\begin{align*}
E \big(\hat{\mathbf{B}} \big) &amp;= E \big((\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} \big) \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T E\big( \mathbf{Y} \big) \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \begin{bmatrix} E(Y_1)^T \\ \vdots \\ E(Y_n)^T \end{bmatrix} \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \begin{bmatrix} x_1^T \mathbf{B} \\ \vdots \\ x_n^T \mathbf{B} \end{bmatrix} \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \begin{bmatrix} x_1^T  \\ \vdots \\ x_n^T \end{bmatrix} \mathbf{B} \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X} \mathbf{B} \\
&amp;= \mathbf{B}
\end{align*}\]</span></p>
<p>Let <span class="math inline">\(\hat{\boldsymbol{\beta}}_j := \hat{\mathbf{B}} e_j\)</span>, the <span class="math inline">\(j\)</span><sup>th</sup> column of <span class="math inline">\(\hat{\mathbf{B}}\)</span>. Then:</p>
<p><span class="math display">\[\begin{align*}
\hat{\boldsymbol{\beta}}_j &amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} e_j \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \big[ \mathbf{X} \mathbf{B} + \boldsymbol{\mathcal{E}} \big] e_j \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \big[ \mathbf{X} \boldsymbol{\beta}_j + \boldsymbol{\mathcal{E}} e_j \big] \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X} \boldsymbol{\beta}_j + (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\mathcal{E}} e_j \\
&amp;= \boldsymbol{\beta}_j + (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\mathcal{E}} e_j
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(\mathcal{E}_i \stackrel{iid}{\sim} N_q(\mathbf{0}, \Sigma)\)</span>, we have <span class="math inline">\(e_j^T \mathcal{E}_i = \varepsilon_{ij} \stackrel{iid}{\sim} N(0, \Sigma_{jj})\)</span>, <span class="math inline">\(i = 1, \dots, n\)</span>. Thus: <span class="math display">\[\boldsymbol{\mathcal{E}} e_j \sim N_n \big(\mathbf{0}, \Sigma_{jj} I_n \big)\]</span> That is: <span class="math display">\[\hat{\boldsymbol{\beta}}_j \sim N_k(\boldsymbol{\beta}_j, \Sigma_{jj} (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1}) = N_k \big(\boldsymbol{\beta}_j, \Sigma_{jj} (\mathbf{X}^T \mathbf{X})^{-1} \big)\]</span></p>
<p>Here, we again confirm that the multivariate response linear regression is just the univariate response linear regression on each <span class="math inline">\(y_j\)</span>.</p>
<p>What about “some extra information about the relationship between parameters”? Let’s start with <span class="math inline">\(\hat{\boldsymbol{\beta}}^i := e_i^T \hat{\mathbf{B}}\)</span>, the <span class="math inline">\(i\)</span><sup>th</sup> row of <span class="math inline">\(\hat{\mathbf{B}}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\hat{\boldsymbol{\beta}}^i &amp;= e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} \\
&amp;= e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \big[ \mathbf{X} \mathbf{B} + \boldsymbol{\mathcal{E}} \big] \\
&amp;= e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X} \mathbf{B} + e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\mathcal{E}} \\
&amp;=: \boldsymbol{\beta}^{i} + e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \boldsymbol{\mathcal{E}} \\
\implies (\hat{\boldsymbol{\beta}}^{i})^{T} - (\boldsymbol{\beta}^{i})^T &amp;= \boldsymbol{\mathcal{E}}^T \mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1} e_i \\
&amp;= \sum_{u = 1}^{n} \mathcal{E}_u \underbrace{x_u^T (\mathbf{X}^T \mathbf{X})^{-1} e_i}_{=\text{constant}} \\
&amp;= \sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] \mathcal{E}_u
\end{align*}\]</span></p>
<p>This implies:</p>
<p><span class="math display">\[\begin{align*}
&amp;\mathcal{E}_u \stackrel{iid}{\sim} N_q \big(\mathbf{0}, \Sigma \big) \\
\implies \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] &amp;\mathcal{E}_u \stackrel{indep}{\sim} N_q \big(\mathbf{0}, \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big]^2 \Sigma \big) \\
\implies \sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] &amp;\mathcal{E}_u \sim N_q \big(\mathbf{0}, \sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big]^2 \Sigma \big)
\end{align*}\]</span></p>
<p>and:</p>
<p><span class="math display">\[\begin{align*}
&amp;\sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big]^2 \Sigma \\ 
&amp;= \sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] \Sigma \\
&amp;= \sum_{u = 1}^{n} \big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} x_u \big] \big[ x_u^T (\mathbf{X}^T \mathbf{X})^{-1} e_i \big] \Sigma \\
&amp;= \Big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \big[ \sum_{u = 1}^{n} x_u x_u^T \big] (\mathbf{X}^T \mathbf{X})^{-1} e_i \Big] \Sigma \\
&amp;= \Big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1} e_i \Big] \Sigma \\
&amp;= \Big[ e_i^T (\mathbf{X}^T \mathbf{X})^{-1} e_i \Big] \Sigma \\
&amp;= (\mathbf{X}^T \mathbf{X})^{-1}_{ii} \Sigma
\end{align*}\]</span></p>
<p>Hence, <span class="math inline">\(\hat{\boldsymbol{\beta}}^{i}\)</span> has the distribution: <span class="math display">\[(\hat{\boldsymbol{\beta}}^{i})^{T} \sim N_q\big((\boldsymbol{\beta}^{i})^T, (\mathbf{X}^T \mathbf{X})^{-1}_{ii} \Sigma \big)\]</span></p>
<p>Let’s interpret this a little: the multivariate response linear regression is about conducting the univariate response linear regression on <span class="math inline">\(y_{.j} (:= y_j)\)</span>’s with the same set of covariates <span class="math inline">\(x_{.} = (x_{.1}, x_{.2}, \dots, x_{.k})\)</span>. So for some fixed <span class="math inline">\(j\)</span>, the <span class="math inline">\(j\)</span><sup>th</sup> univariate response, <span class="math inline">\(y_{.j}\)</span>, in <span class="math inline">\(Y_{.} = (y_{.1}, \dots, y_{.q})\)</span> will have a model: <span class="math display">\[y_{.j} = x_{.}^T \boldsymbol{\beta}_j + \varepsilon_{.j}\]</span> where <span class="math inline">\(\varepsilon_{.j} \sim N(0, \Sigma_{jj})\)</span>. That is, for <span class="math inline">\(i = 1, \dots, n\)</span>, <span class="math inline">\(y_{ij}\)</span> has a model: <span class="math display">\[y_{ij} = x_{i}^T \boldsymbol{\beta}_j + \varepsilon_{ij}\]</span> with <span class="math inline">\(\varepsilon_{ij} \stackrel{iid}{\sim} N(0, \Sigma_{jj})\)</span>.</p>
<p>And since we are using the same set of covariates, there should be a <span class="math inline">\(p\)</span><sup>th</sup> element (<span class="math inline">\(p \in \{1, \dots, k\}\)</span>) in every <span class="math inline">\(\boldsymbol{\beta}_j = (\dots, \text{ } \beta_{pj}, \text{ } \dots)\)</span> for each <span class="math inline">\(y_{.j}\)</span> that corresponds to <span class="math inline">\(x_{.p}\)</span>. The collection of such <span class="math inline">\(p\)</span><sup>th</sup> elements, <span class="math inline">\((\beta_{p1}, \dots, \beta_{pj}, \dots, \beta_{pq})\)</span>, is the <span class="math inline">\(p\)</span><sup>th</sup> row of <span class="math inline">\(\mathbf{B}\)</span>, i.e. <span class="math display">\[\boldsymbol{\beta}^{\text{ }p} = (\beta_{p1}, \dots, \beta_{pj}, \dots, \beta_{pq}) = e_p^T\mathbf{B}\]</span></p>
<p>The MLE of this <span class="math inline">\(\boldsymbol{\beta}^{\text{ }p}\)</span> is <span class="math inline">\(\hat{\boldsymbol{\beta}}^{\text{ }p}\)</span> with <span class="math inline">\(Var((\hat{\boldsymbol{\beta}}^{\text{ }p})^T) = (\mathbf{X}^T \mathbf{X})^{-1}_{pp} \Sigma\)</span>. That is, if we assume that each <span class="math inline">\(y_{.j}\)</span> in <span class="math inline">\(Y_.\)</span> are correlated (so that <span class="math inline">\(Var(Y_.) = \Sigma\)</span>) and conduct linear regressions on each <span class="math inline">\(y_{.j}\)</span> using the same covariates, then the MLEs for the <span class="math inline">\(p\)</span><sup>th</sup> parameter which corresponds to <span class="math inline">\(x_{.p}\)</span> in each regression are correlated as well. Namely, <span class="math inline">\((\hat{\boldsymbol{\beta}}^{\text{ }p})^T \sim N_q(\boldsymbol{\beta}^{\text{ }p}, (\mathbf{X}^T \mathbf{X})^{-1}_{pp} \Sigma)\)</span>.</p>
<p>So it starts with an assumption that there is a relationship between different <span class="math inline">\(y_{.j}\)</span>’s, and concludes that MLEs for the <span class="math inline">\(p\)</span><sup>th</sup> parameter are correlated in linear regressions.</p>
<p>We shall now see <span class="math inline">\(\hat{\Sigma}\)</span>, the MLE for <span class="math inline">\(\Sigma\)</span>.</p>
</div>
<div id="hatsigma" class="section level3">
<h3><span class="math inline">\(\hat{\Sigma}\)</span></h3>
<p>To find the distribution of <span class="math inline">\(\hat{\Sigma}\)</span> — yes, you heard it right; the distribution of a <strong>matrix</strong> — first note that:</p>
<p><span class="math display">\[\begin{align*}
(I_n - H) \mathbf{X} \mathbf{B} &amp;= \mathbf{X} \mathbf{B} - H \mathbf{X} \mathbf{B} \\
&amp;= \mathbf{X} \mathbf{B} - \mathbf{X} ( \mathbf{X}^T  \mathbf{X})^{-1} \mathbf{X}^T  \mathbf{X} \mathbf{B} \\
&amp;= \mathbf{X} \mathbf{B} -  \mathbf{X} \mathbf{B} \\
&amp;= \mathbf{O}
\end{align*}\]</span></p>
<p>and:</p>
<ul>
<li><span class="math inline">\((I_n - H)^T = (I_n - H^T) = (I_n - \mathbf{X} ( \mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T) = I_n - H\)</span> (i.e. symmetric)
<ul>
<li>i.e. <span class="math inline">\(I_n - H = U \Lambda U^T\)</span> for some <span class="math inline">\(U\)</span> and <span class="math inline">\(\Lambda\)</span> by spectral decomposition</li>
</ul></li>
<li><span class="math inline">\((I_n - H)^2 = (I_n - H)(I_n - H) = I_n - 2H + H^2 = I_n - H\)</span> (i.e. idempotent)
<ul>
<li>i.e. eigenvalues of <span class="math inline">\(I_n - H\)</span> are either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span></li>
</ul></li>
<li><span class="math inline">\(\text{tr}(I_n - H) = \text{tr}(I_n) - \text{tr}(H) = n - \text{tr}( (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{X}) = n - k\)</span>
<ul>
<li>i.e. <span class="math inline">\(1\)</span> has the multiplicity <span class="math inline">\(n - k\)</span> (<span class="math inline">\(= \text{tr}(I_n - H)\)</span>), and <span class="math inline">\(0\)</span> has the multiplicity <span class="math inline">\(k\)</span></li>
<li>i.e. <span class="math inline">\(\text{rank}(I_n - H) = n - k\)</span></li>
</ul></li>
<li><span class="math inline">\(I_n - H = U \Lambda U^T = U \begin{bmatrix} I_{n - k} &amp; \mathbf{O} \\ \mathbf{O} &amp; \mathbf{O} \end{bmatrix}_{n \times n} U^T = \sum_{s = 1}^{n - k} u_s u_s^T\)</span></li>
</ul>
<p>Also, notice that <span class="math inline">\(n \hat{\Sigma} = C\)</span>, where <span class="math inline">\(C = C(\hat{\mathbf{B}}, \mathbf{Y}, \mathbf{X}) = \mathbf{Y}^T (I_n - H)\mathbf{Y}\)</span>, and:</p>
<p><span class="math display">\[\begin{align*}
(\mathbf{Y} - \mathbf{X} \mathbf{B} )^T (I_n - H) (\mathbf{Y} - \mathbf{X} \mathbf{B}) &amp;= (\mathbf{Y}^T - \mathbf{B}^T \mathbf{X}^T) (I_n - H) (\mathbf{Y} - \mathbf{X} \mathbf{B}) \\
&amp;= (\mathbf{Y}^T - \mathbf{B}^T \mathbf{X}^T) ( (I_n - H) \mathbf{Y} - \underbrace{ (I_n - H) \mathbf{X} \mathbf{B}}_{=\mathbf{O}} ) \\
&amp;= (\mathbf{Y}^T - \mathbf{B}^T \mathbf{X}^T)  (I_n - H) \mathbf{Y} \\
&amp;= \mathbf{Y}^T (I_n - H) \mathbf{Y} - \mathbf{B}^T \mathbf{X}^T (I_n - H) \mathbf{Y} \\
&amp;= \mathbf{Y}^T (I_n - H) \mathbf{Y} - \Big[ \underbrace{(I_n - H) \mathbf{X} \mathbf{B}}_{=\mathbf{O}} \Big]^T  \mathbf{Y} \\
&amp;= \mathbf{Y}^T (I_n - H) \mathbf{Y}
\end{align*}\]</span></p>
<p>That is: <span class="math display">\[(\mathbf{Y} - \mathbf{X} \mathbf{B} )^T (I_n - H) (\mathbf{Y} - \mathbf{X} \mathbf{B}) = \boldsymbol{\mathcal{E}}^T (I_n - H) \boldsymbol{\mathcal{E}} = \mathbf{Y}^T (I_n - H) \mathbf{Y}\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[\begin{align*}
C &amp;= \mathbf{Y}^T (I_n - H) \mathbf{Y} = \boldsymbol{\mathcal{E}}^T (I_n - H) \boldsymbol{\mathcal{E}} \\
&amp;= \boldsymbol{\mathcal{E}}^T \big[ \sum_{s = 1}^{n - k} u_s u_s^T \big] \boldsymbol{\mathcal{E}} \\
&amp;= \sum_{s = 1}^{n - k} \boldsymbol{\mathcal{E}}^T  u_s u_s^T \boldsymbol{\mathcal{E}} \\
&amp;= \sum_{s = 1}^{n - k} \big[ \boldsymbol{\mathcal{E}}^T  u_s \big] \big[ \boldsymbol{\mathcal{E}}^T u_s \big]^T \\
&amp;= \sum_{s = 1}^{n - k} Z_s Z_s^T
\end{align*}\]</span></p>
<p>Recall <span class="math inline">\(\boldsymbol{\mathcal{E}} e_j \sim N_n (\mathbf{0}, \Sigma_{jj} I_n)\)</span>, so that <span class="math inline">\(u_s^T \boldsymbol{\mathcal{E}} e_j \sim N(0, \Sigma_{jj} u_s^T u_s) = N(0, \Sigma_{jj})\)</span>. This implies:</p>
<p><span class="math display">\[\begin{align*}
Z_s = \boldsymbol{\mathcal{E}}^T u_s = \begin{bmatrix} e_1^T \boldsymbol{\mathcal{E}}^T u_s \\ \vdots \\ e_q^T \boldsymbol{\mathcal{E}}^T u_s \end{bmatrix}_{q \times 1} = \begin{bmatrix} u_s^T \boldsymbol{\mathcal{E}} e_1 \\ \vdots \\ u_s^T \boldsymbol{\mathcal{E}} e_q \end{bmatrix} \sim N_q
\end{align*}\]</span></p>
<p>Computing <span class="math inline">\(Cov(Z_{sv}, Z_{sw})\)</span>, the covariance of two arbitrary components of <span class="math inline">\(Z_s\)</span>, yields:</p>
<p><span class="math display">\[\begin{align*}
Cov(Z_{sv}, Z_{sw}) &amp;:= Cov(u_s^T \boldsymbol{\mathcal{E}} e_v, u_s^T \boldsymbol{\mathcal{E}} e_w) \\
&amp;:= Cov(u_s^T m_v, u_s^T m_w) \\
&amp;= u_s^T Cov(m_v, m_w) u_s \\
&amp;= u_s^T \Sigma_{vw} I_n u_s = \Sigma_{vw} \underbrace{u_s^T u_s}_{=1} = \Sigma_{vw}
\end{align*}\]</span></p>
<p>since rows of <span class="math inline">\(\boldsymbol{\mathcal{E}}\)</span> are iid. In other words: <span class="math display">\[Z_s \sim N_q (\mathbf{0}, \Sigma)\]</span></p>
<p>Lastly, we check the value of <span class="math inline">\(Cov(Z_s, Z_t)\)</span>, a <span class="math inline">\(q \times q\)</span> matrix:</p>
<p><span class="math display">\[\begin{align*}
Cov(Z_{sv}, Z_{tw}) &amp;= E\Big[ u_s^T \boldsymbol{\mathcal{E}} e_v e_w^T \boldsymbol{\mathcal{E}}^T u_t \Big] \\ 
&amp;= E\Big[ u_s^T m_v m_w^T u_t \Big] \\
&amp;= u_s^T E\Big[ m_v m_w^T \Big] u_t \\
&amp;= u_s^T \Big[ Cov(m_v, m_w) \Big] u_t \\
&amp;= \Sigma_{vw} \underbrace{u_s^T u_t}_{=0} = 0 \\
\implies Cov(Z_s, Z_t) &amp;= \mathbf{O} 
\end{align*}\]</span></p>
<p>Hence: <span class="math display">\[\mathbf{Z} := \begin{bmatrix} Z_1 \\ \vdots \\ Z_{n - k} \end{bmatrix} \sim N_{q(n - k)} \Big(\mathbf{0}, \boldsymbol{\Sigma} = \begin{bmatrix} \Sigma &amp; \mathbf{O} &amp; \dots &amp; \mathbf{O} \\ \mathbf{O} &amp; \Sigma &amp; \dots &amp; \mathbf{O} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \mathbf{O} &amp; \mathbf{O} &amp; \dots &amp; \Sigma \end{bmatrix} \Big)\]</span></p>
<p>That is, <span class="math inline">\(Z_s \stackrel{iid}{\sim} N_q(\mathbf{0}, \Sigma)\)</span>. Therefore, <span class="math inline">\(C\)</span> has the <a href="https://en.wikipedia.org/wiki/Wishart_distribution">Wishart distribution</a>, or: <span class="math display">\[n \hat{\Sigma} = C = \sum_{s = 1}^{n - k} Z_s Z_s^T \sim W_q(\Sigma, n - k)\]</span></p>
<p>and so: <span class="math display">\[E(n \hat{\Sigma}) = (n - k)\Sigma\]</span> or: <span class="math display">\[E(\hat{\Sigma}) = \frac{n - k}{n} \Sigma\]</span></p>
<p>So the MLE for <span class="math inline">\(\Sigma\)</span> is biased. Similar to the univariate case, <span class="math inline">\(\widetilde{\Sigma} := \frac{n}{n - k} \hat{\Sigma}\)</span> is unbiased.</p>
<p><strong>Aside 2</strong>: So far, we’ve seen the following unbiased estimates of variabilities:</p>
<ul>
<li>the total variability: <span class="math inline">\(S_\mathbf{Y} := \frac{1}{n - 1} \mathbf{Y}^T (I_n - \frac{1}{n} \mathbf{1} \mathbf{1}^T) \mathbf{Y}\)</span></li>
<li>the variability in error terms: <span class="math inline">\(\widetilde{\Sigma} = \frac{n}{n - k} \hat{\Sigma} = \frac{1}{n - k} \mathbf{Y}^T (I_n - H) \mathbf{Y}\)</span></li>
</ul>
<p>Given these two, we can make another one:</p>
<p><span class="math display">\[\begin{align*}
(n - 1) S_{\mathbf{Y}} &amp;= \mathbf{Y}^T (I_n - \frac{1}{n} \mathbf{1} \mathbf{1}^T) \mathbf{Y} \\
&amp;= \mathbf{Y}^T (I_n - H + H - \frac{1}{n} \mathbf{1} \mathbf{1}^T) \mathbf{Y} \\
&amp;= \mathbf{Y}^T \big( (I_n - H)\mathbf{Y} + (H - \frac{1}{n} \mathbf{1} \mathbf{1}^T)\mathbf{Y} \big) \\
&amp;= \mathbf{Y}^T (I_n - H)\mathbf{Y} + \mathbf{Y}^T (H - \frac{1}{n} \mathbf{1} \mathbf{1}^T)\mathbf{Y} \\
&amp;= (n - k) \widetilde{\Sigma} + \mathbf{Y}^T (H - \frac{1}{n} \mathbf{1} \mathbf{1}^T)\mathbf{Y}
\end{align*}\]</span></p>
<p>Say <span class="math inline">\(M := \frac{1}{k - 1} \mathbf{Y}^T (H - \frac{1}{n} \mathbf{1} \mathbf{1}^T)\mathbf{Y}\)</span>. Then: <span class="math display">\[(n - 1) S_{\mathbf{Y}} = (n - k) \widetilde{\Sigma} + (k - 1) M\]</span></p>
<p>This <span class="math inline">\(M\)</span> is, in fact, the variability explained by the chosen covariates (or the “model”).</p>
<p><strong>Aside 3</strong>: There is a proposition which states that if <span class="math inline">\(X_i \stackrel{iid}{\sim} N_d(\mu, \Sigma)\)</span>, then <span class="math inline">\(\overline{X} \sim N_d(\mu, \frac{1}{n}\Sigma)\)</span> and <span class="math inline">\((n - 1)S = \sum_{i = 1}^{n} (X_i - \overline{X})(X_i - \overline{X})^T \sim W_d(\Sigma, n - 1)\)</span> are independent. It is tempting to say the same for <span class="math inline">\(\overline{Y}\)</span> and <span class="math inline">\((n - 1)S_{\mathbf{Y}}\)</span>, but we can’t do that; <span class="math inline">\(Y_i\)</span>’s are mutually independent, but not identically distributed.</p>
</div>
</div>
</div>
<div id="an-example-iris" class="section level1">
<h1>3. An example: <code>iris</code></h1>
<p>There are five variables in <code>iris</code> dataset:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">glimpse</span>(iris)</a></code></pre></div>
<pre><code>## Observations: 150
## Variables: 5
## $ Sepal.Length &lt;dbl&gt; 5.1,...
## $ Sepal.Width  &lt;dbl&gt; 3.5,...
## $ Petal.Length &lt;dbl&gt; 1.4,...
## $ Petal.Width  &lt;dbl&gt; 0.2,...
## $ Species      &lt;fct&gt; seto...</code></pre>
<p>We first see that <span class="math inline">\(n = 150\)</span>. I will let <span class="math inline">\(q = 2\)</span> by setting <code>Petal.Length</code> and <code>Petal.Width</code> as a response vector, and <span class="math inline">\(k = 3\)</span> including the intercept and excluding <code>Species</code>. The following matrices will be defined:</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span></li>
<li><span class="math inline">\(\mathbf{Y}\)</span></li>
<li><span class="math inline">\(A := (\mathbf{X}^T \mathbf{X})^{-1}\)</span></li>
<li><span class="math inline">\(\mathbf{H} = \mathbf{X} A \mathbf{X}^T\)</span></li>
<li><span class="math inline">\(I_n\)</span></li>
<li><span class="math inline">\(C_{\text{_}} = \mathbf{Y}^T (I_n - H) \mathbf{Y}\)</span></li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(iris)</a>
<a class="sourceLine" id="cb4-2" title="2">X &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="st">    </span><span class="kw">select</span>(Sepal.Length, Sepal.Width) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">int =</span> <span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">n</span>())) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb4-5" title="5"><span class="st">    </span><span class="kw">as.matrix</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb4-6" title="6"><span class="st">    &#39;[&#39;</span>(, <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb4-7" title="7">Y &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb4-8" title="8"><span class="st">    </span><span class="kw">select</span>(Petal.Length, Petal.Width) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb4-9" title="9"><span class="st">    </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb4-10" title="10">A &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X)</a>
<a class="sourceLine" id="cb4-11" title="11">H &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>A <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X)</a>
<a class="sourceLine" id="cb4-12" title="12">I_n &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">1</span>, n)</a>
<a class="sourceLine" id="cb4-13" title="13">C_ &lt;-<span class="st"> </span><span class="kw">t</span>(Y) <span class="op">%*%</span><span class="st"> </span>(I_n <span class="op">-</span><span class="st"> </span>H) <span class="op">%*%</span><span class="st"> </span>Y <span class="co"># n * SigmaHat</span></a>
<a class="sourceLine" id="cb4-14" title="14">k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)</a></code></pre></div>
<p>We can now compute <span class="math inline">\(\hat{\mathbf{B}} = A \mathbf{X}^T \mathbf{Y}\)</span> and <span class="math inline">\(\widetilde{\Sigma} = S = \frac{n}{n - k} \hat{\Sigma} = \frac{1}{n - k} C_{\text{_}}\)</span>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">(B &lt;-<span class="st"> </span>A <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Y)</a></code></pre></div>
<pre><code>##              Petal.Length
## int             -2.524762
## Sepal.Length     1.775593
## Sepal.Width     -1.338623
##              Petal.Width
## int           -1.5634923
## Sepal.Length   0.7232920
## Sepal.Width   -0.4787213</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">(S &lt;-<span class="st"> </span>C_ <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>k))</a></code></pre></div>
<pre><code>##              Petal.Length
## Petal.Length    0.4179371
## Petal.Width     0.2190338
##              Petal.Width
## Petal.Length   0.2190338
## Petal.Width    0.1513926</code></pre>
<p>Notice that the first column of <code>B</code> is exactly the same as the parameters obtained by the univariate response linear regression on <code>Petal.Length</code>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1">mod_pl &lt;-<span class="st"> </span><span class="kw">lm</span>(Petal.Length <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width, <span class="dt">data =</span> iris)</a>
<a class="sourceLine" id="cb9-2" title="2"><span class="kw">coef</span>(mod_pl)</a></code></pre></div>
<pre><code>##  (Intercept) Sepal.Length 
##    -2.524762     1.775593 
##  Sepal.Width 
##    -1.338623</code></pre>
<p>The variance of <span class="math inline">\(\hat{\boldsymbol{\beta}}_{P.L.}\)</span>, which can be obtained by <code>vcov(mod_pl)</code>, is exactly equal to <span class="math inline">\(S_{11} A\)</span>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="kw">vcov</span>(mod_pl) <span class="co"># variance matrix of the parameter estimates</span></a></code></pre></div>
<pre><code>##              (Intercept)
## (Intercept)   0.31746425
## Sepal.Length -0.02707082
## Sepal.Width  -0.05118649
##               Sepal.Length
## (Intercept)  -0.0270708209
## Sepal.Length  0.0041480076
## Sepal.Width   0.0009265034
##                Sepal.Width
## (Intercept)  -0.0511864936
## Sepal.Length  0.0009265034
## Sepal.Width   0.0149714213</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1">S[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>A <span class="co"># variance of the 1st column of B</span></a></code></pre></div>
<pre><code>##                      int
## int           0.31746425
## Sepal.Length -0.02707082
## Sepal.Width  -0.05118649
##               Sepal.Length
## int          -0.0270708209
## Sepal.Length  0.0041480076
## Sepal.Width   0.0009265034
##                Sepal.Width
## int          -0.0511864936
## Sepal.Length  0.0009265034
## Sepal.Width   0.0149714213</code></pre>
<p>The same goes for the second column of <code>B</code> as well:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">mod_pw &lt;-<span class="st"> </span><span class="kw">lm</span>(Petal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width, <span class="dt">data =</span> iris)</a>
<a class="sourceLine" id="cb15-2" title="2"><span class="kw">coef</span>(mod_pw)</a></code></pre></div>
<pre><code>##  (Intercept) Sepal.Length 
##   -1.5634923    0.7232920 
##  Sepal.Width 
##   -0.4787213</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1"><span class="kw">vcov</span>(mod_pw)</a></code></pre></div>
<pre><code>##               (Intercept)
## (Intercept)   0.114997519
## Sepal.Length -0.009806072
## Sepal.Width  -0.018541678
##               Sepal.Length
## (Intercept)  -0.0098060718
## Sepal.Length  0.0015025647
## Sepal.Width   0.0003356145
##                Sepal.Width
## (Intercept)  -0.0185416776
## Sepal.Length  0.0003356145
## Sepal.Width   0.0054232132</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1">S[<span class="dv">2</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>A <span class="co"># 2nd column</span></a></code></pre></div>
<pre><code>##                       int
## int           0.114997519
## Sepal.Length -0.009806072
## Sepal.Width  -0.018541678
##               Sepal.Length
## int          -0.0098060718
## Sepal.Length  0.0015025647
## Sepal.Width   0.0003356145
##                Sepal.Width
## int          -0.0185416776
## Sepal.Length  0.0003356145
## Sepal.Width   0.0054232132</code></pre>
<p>The variances of the <span class="math inline">\(i\)</span><sup>th</sup> row of <code>B</code>, <span class="math inline">\(i = 1, 2, 3\)</span>, can be computed as <span class="math inline">\(A_{11} S\)</span>, <span class="math inline">\(A_{22} S\)</span>, and <span class="math inline">\(A_{33} S\)</span> respectively:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">A[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>S <span class="co"># 1st row, using unbiased estimator</span></a></code></pre></div>
<pre><code>##              Petal.Length
## Petal.Length    0.3174643
## Petal.Width     0.1663777
##              Petal.Width
## Petal.Length   0.1663777
## Petal.Width    0.1149975</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1">A[<span class="dv">2</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>S <span class="co"># 2nd row</span></a></code></pre></div>
<pre><code>##              Petal.Length
## Petal.Length  0.004148008
## Petal.Width   0.002173901
##              Petal.Width
## Petal.Length 0.002173901
## Petal.Width  0.001502565</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1">A[<span class="dv">3</span>, <span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>S <span class="co"># 3rd row</span></a></code></pre></div>
<pre><code>##              Petal.Length
## Petal.Length  0.014971421
## Petal.Width   0.007846269
##              Petal.Width
## Petal.Length 0.007846269
## Petal.Width  0.005423213</code></pre>
<p>Now let’s use the built-in <code>lm</code> function:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1">mod_mv &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>])</a>
<a class="sourceLine" id="cb27-2" title="2"><span class="kw">summary</span>(mod_mv)</a></code></pre></div>
<pre><code>## Response Petal.Length :
## 
## Call:
## lm(formula = Petal.Length ~ Sepal.Length + Sepal.Width, data = iris[, 
##     1:2])
## 
## Residuals:
##      Min       1Q   Median 
## -1.25582 -0.46922 -0.05741 
##       3Q      Max 
##  0.45530  1.75599 
## 
## Coefficients:
##              Estimate
## (Intercept)  -2.52476
## Sepal.Length  1.77559
## Sepal.Width  -1.33862
##              Std. Error
## (Intercept)     0.56344
## Sepal.Length    0.06441
## Sepal.Width     0.12236
##              t value Pr(&gt;|t|)
## (Intercept)   -4.481 1.48e-05
## Sepal.Length  27.569  &lt; 2e-16
## Sepal.Width  -10.940  &lt; 2e-16
##                 
## (Intercept)  ***
## Sepal.Length ***
## Sepal.Width  ***
## ---
## Signif. codes:  
##   0 &#39;***&#39; 0.001 &#39;**&#39; 0.01
##   &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6465 on 147 degrees of freedom
## Multiple R-squared:  0.8677, Adjusted R-squared:  0.8659 
## F-statistic:   482 on 2 and 147 DF,  p-value: &lt; 2.2e-16
## 
## 
## Response Petal.Width :
## 
## Call:
## lm(formula = Petal.Width ~ Sepal.Length + Sepal.Width, data = iris[, 
##     1:2])
## 
## Residuals:
##     Min      1Q  Median 
## -0.7231 -0.2973 -0.0566 
##      3Q     Max 
##  0.1929  1.1088 
## 
## Coefficients:
##              Estimate
## (Intercept)  -1.56349
## Sepal.Length  0.72329
## Sepal.Width  -0.47872
##              Std. Error
## (Intercept)     0.33911
## Sepal.Length    0.03876
## Sepal.Width     0.07364
##              t value Pr(&gt;|t|)
## (Intercept)   -4.611 8.66e-06
## Sepal.Length  18.659  &lt; 2e-16
## Sepal.Width   -6.501 1.17e-09
##                 
## (Intercept)  ***
## Sepal.Length ***
## Sepal.Width  ***
## ---
## Signif. codes:  
##   0 &#39;***&#39; 0.001 &#39;**&#39; 0.01
##   &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3891 on 147 degrees of freedom
## Multiple R-squared:  0.7429, Adjusted R-squared:  0.7394 
## F-statistic: 212.4 on 2 and 147 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The <code>Std. Error</code> are just square roots of diagonal entries in variance estimators of <span class="math inline">\(\hat{\boldsymbol{\beta}}_j\)</span>’s:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1"><span class="kw">sqrt</span>(<span class="kw">diag</span>(S[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>A))</a></code></pre></div>
<pre><code>##          int Sepal.Length 
##   0.56343966   0.06440503 
##  Sepal.Width 
##   0.12235776</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="kw">sqrt</span>(<span class="kw">diag</span>(S[<span class="dv">2</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>A))</a></code></pre></div>
<pre><code>##          int Sepal.Length 
##   0.33911284   0.03876293 
##  Sepal.Width 
##   0.07364247</code></pre>
<p>We can obtain <code>B</code> by:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"><span class="kw">coef</span>(mod_mv)</a></code></pre></div>
<pre><code>##              Petal.Length
## (Intercept)     -2.524762
## Sepal.Length     1.775593
## Sepal.Width     -1.338623
##              Petal.Width
## (Intercept)   -1.5634923
## Sepal.Length   0.7232920
## Sepal.Width   -0.4787213</code></pre>
<p>Finally, let’s see what <code>vcov(mod_mv)</code> returns:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1">rows &lt;-<span class="st"> </span><span class="kw">rownames</span>(<span class="kw">vcov</span>(mod_mv))</a>
<a class="sourceLine" id="cb35-2" title="2"><span class="st">&#39;rownames&lt;-&#39;</span>(<span class="kw">as.data.frame</span>(<span class="kw">vcov</span>(mod_mv)), rows)</a></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Petal.Length:(Intercept)"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Petal.Length:Sepal.Length"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Petal.Length:Sepal.Width"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Petal.Width:(Intercept)"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Petal.Width:Sepal.Length"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Petal.Width:Sepal.Width"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.31746425","2":"-0.0270708209","3":"-0.0511864936","4":"0.166377653","5":"-0.0141873601","6":"-0.0268259770","_rn_":"Petal.Length:(Intercept)"},{"1":"-0.02707082","2":"0.0041480076","3":"0.0009265034","4":"-0.014187360","5":"0.0021739008","6":"0.0004855648","_rn_":"Petal.Length:Sepal.Length"},{"1":"-0.05118649","2":"0.0009265034","3":"0.0149714213","4":"-0.026825977","5":"0.0004855648","6":"0.0078462691","_rn_":"Petal.Length:Sepal.Width"},{"1":"0.16637765","2":"-0.0141873601","3":"-0.0268259770","4":"0.114997519","5":"-0.0098060718","6":"-0.0185416776","_rn_":"Petal.Width:(Intercept)"},{"1":"-0.01418736","2":"0.0021739008","3":"0.0004855648","4":"-0.009806072","5":"0.0015025647","6":"0.0003356145","_rn_":"Petal.Width:Sepal.Length"},{"1":"-0.02682598","2":"0.0004855648","3":"0.0078462691","4":"-0.018541678","5":"0.0003356145","6":"0.0054232132","_rn_":"Petal.Width:Sepal.Width"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>It returns a <span class="math inline">\(6 \times 6\)</span> matrix where:</p>
<ul>
<li>Entries with the name <code>(Intercept)</code> are the same as <span class="math inline">\(A_{11} S\)</span></li>
<li>Entries with the name <code>Sepal.Length</code> are the same as <span class="math inline">\(A_{22} S\)</span></li>
<li>Entries with the name <code>Sepal.Width</code> are the same as <span class="math inline">\(A_{33} S\)</span></li>
<li>Entries with the name <code>Petal.Length</code> are the same as <span class="math inline">\(S_{11} A\)</span> (which explains 9 entries in the upper left corner)</li>
<li>Entries with the name <code>Petal.Width</code> are the same as <span class="math inline">\(S_{22} A\)</span> (which explains 9 entries in the lower right corner)</li>
</ul>
<p>Moreover:</p>
<ul>
<li>9 entries in the upper right corner are the same as <span class="math inline">\(S_{12} A\)</span> (the covariance of <span class="math inline">\(\hat{\boldsymbol{\beta}}_{PL}\)</span> and <span class="math inline">\(\hat{\boldsymbol{\beta}}_{PW}\)</span>)</li>
<li>9 entries in the lower left corner are the same as <span class="math inline">\(S_{21} A = [S_{12} A]^T = S_{12} A\)</span></li>
</ul>
<p>Basically, <code>vcov(mod_mv)</code> returns every possible pair of two individual one-dimensional estimators and their covariance.</p>
</div>
<div id="session-info" class="section level1">
<h1>Session info</h1>
<p>R session info:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1"><span class="kw">sessionInfo</span>()</a></code></pre></div>
<pre><code>## R version 3.6.1 (2019-07-05)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Canada.1252 
## [2] LC_CTYPE=English_Canada.1252   
## [3] LC_MONETARY=English_Canada.1252
## [4] LC_NUMERIC=C                   
## [5] LC_TIME=English_Canada.1252    
## 
## attached base packages:
## [1] stats     graphics 
## [3] grDevices utils    
## [5] datasets  methods  
## [7] base     
## 
## other attached packages:
##  [1] tidyr_1.0.0       
##  [2] gganimate_1.0.4   
##  [3] ggConvexHull_0.1.0
##  [4] dplyr_0.8.3       
##  [5] reticulate_1.13   
##  [6] pROC_1.15.3       
##  [7] ggrepel_0.8.1     
##  [8] ggplot2_3.2.1     
##  [9] funpark_0.2.6     
## [10] data.table_1.12.6 
## [11] boot_1.3-22       
## [12] rmarkdown_1.17    
## [13] magrittr_1.5      
## [14] itertools2_0.1.1  
## 
## loaded via a namespace (and not attached):
##  [1] progress_1.2.2   
##  [2] prettydoc_0.3.1  
##  [3] tidyselect_0.2.5 
##  [4] xfun_0.11        
##  [5] purrr_0.3.3      
##  [6] lattice_0.20-38  
##  [7] colorspace_1.4-1 
##  [8] vctrs_0.2.0      
##  [9] htmltools_0.4.0  
## [10] yaml_2.2.0       
## [11] utf8_1.1.4       
## [12] rlang_0.4.2      
## [13] pillar_1.4.2     
## [14] glue_1.3.1       
## [15] withr_2.1.2      
## [16] tweenr_1.0.1     
## [17] lifecycle_0.1.0  
## [18] plyr_1.8.4       
## [19] stringr_1.4.0    
## [20] munsell_0.5.0    
## [21] gtable_0.3.0     
## [22] evaluate_0.14    
## [23] labeling_0.3     
## [24] knitr_1.26       
## [25] gifski_0.8.6     
## [26] fansi_0.4.0      
## [27] Rcpp_1.0.3       
## [28] readr_1.3.1      
## [29] scales_1.1.0     
## [30] backports_1.1.5  
## [31] jsonlite_1.6     
## [32] farver_2.0.1     
## [33] gridExtra_2.3    
## [34] png_0.1-7        
## [35] hms_0.5.2        
## [36] digest_0.6.23    
## [37] stringi_1.4.3    
## [38] grid_3.6.1       
## [39] cli_1.1.0        
## [40] tools_3.6.1      
## [41] lazyeval_0.2.2   
## [42] tibble_2.1.3     
## [43] crayon_1.3.4     
## [44] pkgconfig_2.0.3  
## [45] zeallot_0.1.0    
## [46] MASS_7.3-51.4    
## [47] ellipsis_0.3.0   
## [48] Matrix_1.2-17    
## [49] prettyunits_1.0.2
## [50] xml2_1.2.2       
## [51] assertthat_0.2.1 
## [52] rstudioapi_0.10  
## [53] iterators_1.0.12 
## [54] R6_2.4.1         
## [55] compiler_3.6.1</code></pre>
</div>
<div id="related-page" class="section level1">
<h1>Related page</h1>
<ul>
<li><a href="matrix_derivatives.html">Justifying matrix derivatives</a></li>
</ul>
</div>
</section>

<!-- Footer -->
<!-- Reference: https://holtzy.github.io/Pimp-my-rmd/ -->
&nbsp; <!-- whitespace -->
<hr /> <!-- line -->
<div class="footer">
    <p style="text-align: center;">
        <a href="../../index.html" style="font-size: 11pt;">Home</a> · <a href="../../projects.html" style="font-size: 11pt;">Projects</a> · <a href="../../research_materials.html" style="font-size: 11pt;">Research materials</a> · <a href="../../files/resume_junkyu_park.pdf" style="font-size: 11pt;">Resume</a>
    </p>
    <p style="text-align: center;">
        © 2019-2020 Junkyu Park<br>Powered by the <a href="https://github.com/yixuan/prettydoc">prettydoc::html_pretty</a> engine<br>Current theme: modified <a href="https://github.com/jasonlong/cayman-theme">Cayman</a>
    </p>
            
    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
            
    <!-- Add font awesome icons -->
    <p style="text-align: center; margin: 5px 0;">
        <span style="color: #555555;"><em>joon3216@gmail.com</em></span>
        <br>
        <ul class="social-network">
            <li class="button"><a href="https://www.facebook.com/asdfzxcvjkl1" class="fa fa-facebook"></a></li>
            <li class="button"><a href="https://github.com/joon3216" class="fa fa-github"></a></li>
            <li class="button"><a href="https://linkedin.com/in/asdfzxcvjkl1/" class="fa fa-linkedin"></a></li>
            <li class="button"><a href="https://twitter.com/joon3216" class="fa fa-twitter"></a></li>
        </ul>
    </p>
</div>
&nbsp; <!-- whitespace -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
